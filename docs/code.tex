
\documentstyle[a4]{article}
\begin{document}
\title{Implementing SDL Semantics}
\author{Graham Wheeler}

\maketitle

\section{Introduction}

This document describes the static and dynamic semantics of SDL,
and the modifications necessary to enable the
existing e-code interpreter to be re-used to implement an SDL virtual
machine system.

The process of compiling and executing
an SDL specification consists of building an
abstract syntax tree $AS_0$ based on the {\em syntax} of SDL, checking
and rewriting this syntax tree according to the static semantics
(Annex F.2) to ensure well-formedness, and then interpreting the
resulting abstract syntax $AS_1$ according to the
dynamic semantics (Annex F.3).
The static semantics describe the mapping from $AS_0$ to $AS_1$. 
This mapping is assisted by the use of additional semantic domains, which
serve a similar purpose to a symbol table in a conventional compiler.

When extending the existing e-code interpreter to handle SDL,
we wish to limit the amount of change required.
This can be done by looking for mappings between each SDL
construct and constructs in Estelle. This will determine the code
to be generated by the compiler. Where no mapping is possible, the
interpreter/e-code must be extended.

\section{The Static Semantics}

The static semantics describe the mapping from $AS_0$ to $AS_1$. In
the process, static semantic checks are performed. While we do not 
perform much of the mapping, we do need to conduct the checks.
Some parts of the mapping {\em are} done; in particular the remote
definitions are resolved into the system subtree rather than being
kept in a separate subtree.

The mapping is performed in the following order:

\begin{itemize}
\item remote references are replaced by their definitions;
\item `conditional compilation' is performed by evaluating all {\tt
select} statements and pruning the tree;
\item the tree is rewritten in $AS_1$ form, during which
a large number of semantics checks are carried out.
\end{itemize}

In the description of the implementation below, we have given
semantic checks that should be performed for each construct. These
checks were obtained from both the SDL Z.100 standard, and the annex
describing the static semantics.

Ideally, we would like a parser that produces $AS_0$, and a rewriter
which produces $AS_1$ from $AS_0$, performing semantic checking,
handling selections, and choosing a consistent subset.
The  output could then be used as input to a code generator or interpreted
directly.
A graphical editor could be built based on the $AS_0$ format.

Unfortunately, time restrictions preclude this.
Instead, we implement the most basic semantic checks and rewriting
in the parser, and output a form which lies between $AS_0$ and
$AS_1$.
This is handled by the checker/code generator which
is to be implemented next, according to the design specified in this
document.
However, the expansion into the full set of $AS_0$/$AS_1$
tools could be done at a later stage, and this document refeects that
possibility.

\section{From concrete syntax to abstract syntax}

In order to interpret an SDL specification, the
original {\em concrete system specification} must be converted
into a {\em consistent partitioning subset}. 
The steps involved in this process are:

\begin{enumerate}
\item the specification is compiled into an abstract syntax tree 
$AS_0$;
\item the tree is rewritten to contain only fundamental SDL 
constructs, resulting in $AS_1$;
\item a consistent partitioning subset is selected for
interpretation, resulting in a set of block IDs of blocks that are
included in the partition;
\item finally, a CSP process named {\em system} is started, and is
passed $AS_1$ and the subset of block IDs as parameters.
\end{enumerate}

Thus far the first step has effectively been implemented (compiling SDL
into $AS_0$, or at least something close to it),
and a decompiler to translate compiled abstract syntax trees
back into textual SDL has also been implemented.

We bypass the second step in our case, as we are using
the {\em PEW} interpreter rather than building a new interpreter for 
$AS_1$ trees. It is as easy to generate e-code from an $AS_0$ tree
as from an $AS_1$ tree. It is worth noting that $AS_1$ trees are
a subset of the set of $AS_0$ trees, so the rewriting phase could be
implemented in the future without affecting the back end.

For a first implementation, we omit the selection of a consistent 
partition. The selection of a consistent partition is only required
when the specification is made up of a set of specifications at
different levels using substructuring. It would be possible to write
a processor that takes an $AS_0$ tree as input, chooses a consistent
partition, and outputs a modified $AS_0'$ tree as output, thus this
step can be done later. For now we disallow channel and block
substructuring, which makes the system as a whole a consistent partition.
Our aim is to produce a useable working subset as soon as possible
and complete the implementation when time permits.

In our case, most of the work to be done to complete the interpreter
involves:

\begin{itemize}
\item implementing those parts of the static semantics pertaining to 
semantic error checking (a small part of this has been done);
\item implementing generation of e-code from the $AS_0$ tree
representation, and modifying the {\em PEW} interpreter where
necessary.
\end{itemize}

The following constructs will not be implemented at first. They are
listed in the order in which they will be implemented if/when time
permits:

\begin{itemize}
\item procedures;
\item selections and transition options;
\item block substructures, and selection of a consistent subset;
\item macros;
\item service decompositions, and priority signals;
\item channel substructures, and selection of a consistent subset;
\item signal refinements.
\end{itemize}

\section{Mapping SDL to Estelle}

We now consider various aspects of SDL and how they relate to similar
concepts in Estelle or in the {\em PEW}.

An SDL specification consists of a system, which is decomposed into
a number of blocks connected by channels. 
The blocks may be decomposed into subblocks, forming a tree structure. 
At the leaf blocks, the blocks contain processes.

Processes within a block communicate with each other over signal
routes, which incur no delay.
Processes can also connect, via signalroutes, to the channels connected
to the surrounding block.
Communication over channels incurs non-deterministic delays.

An important point to note is the level at which all of this occurs.
Channels and their block endpoints are defined at the system level.
Signal routes are defined and connected to channels at the block level.
Block substructures can contain subchannel definitions and connect
subchannels to channels.
All of these are static entities, which means that the connections are
for process {\em types} rather than {\em instances}. 
Each instance of a process type can communicate via the same channels 
but its own copies of the signal routes. 

Once a signal is sent to a destination process, it is placed in
a single input port queue.
There is an implicit signal route from each process back to itself.

Much of this can be modelled in Estelle by having a hierarchy
of passive systems (that is, systems that have an initialisation
transition but no body transitions), one corresponding to each block.
Each process corresponds to an active system whose parent is passive.
We now consider some of these and other aspects in more detail.

\subsection{Predefined Types}

The following types are predefined in SDL:

\begin{itemize}
\item {\tt Boolean}
\item {\tt Character}
\item {\tt Charstring}
\item {\tt Integer}
\item {\tt Natural}
\item {\tt Real}
\item {\tt PId}
\item {\tt Duration}
\item {\tt Time}
\end{itemize}

In addition, SDL includes predefined generators for constructing
strings, arrays and powersets.

At present the {\em PEW} does not support real-valued types, so
the {\tt Real}, {\tt Duration} and {\tt Time} types are a problem.
{\tt PId}'s can be represented as integers.
Initially the {\tt real} type will not be implemented,
and {\tt Duration} and {\tt Time} will be implemented as
integers rather than reals. 

The parser supports the creation of structured (aggregate) types,
and arrays. 
It could be extended later to support subranges for implementing SDL syntypes.

These restrictions are a consequence of the difficulties of
implementing SDL abstract data types, which are possibly more complex 
than the rest of the language in its entirety. 
The motivation is that for specifying protocols for the purposes
of modelling and simulation, structures and arrays of integers 
and characters are sufficient.

\subsection{Process Creation and Termination}

In SDL, any process can create any other process, while in Estelle, 
a process can only create instances of process types that are defined
within its scope. 
Processes are identied in Estelle by module
variables (whose values in the {\em PEW} contain the index into
the parent process' fixed-size process table).
In SDL processes are identified by system-wide unique process
identifiers.

The {\tt init} instruction in the {\em PEW} will be modified
to create a new {\tt sdlinit} instruction to handle the SDL case.
This must also take into account the maximum allowed number of 
instances of each process type.

In Estelle a process can only be terminated by its parent, while in
SDL a process may only terminate itself. 
The {\em terminate} e-code instruction will have to be modified to 
handle the SDL case.
This instruction usually takes a child process index as its argument,
so an argument of -1 can be used to indicate the process itself.

It is intended to reimplement the {\em PEW} interpreter as a set of
C++ classes.
In particular, there will be classes for processes, transitions,
SDL procedures, the scheduler, Estelle interaction points, and SDL
paths.
The {\tt init} and {\tt sdlinit} instructions will have their
common code included in the C++ constructor function for objects of
the {\tt process} class.

\subsection{Procedures}
\label{sdlproc}

Unlike Estelle procedures, SDL procedures are also finite-state
machines, very similar to processes.
The {\em PEW} interpreter and
scheduler will have to be modified to support this.
We cannot simply make these new processes as they can be nested
and access variables in higher scope levels. 
Instead a hybrid approach is needed - entering a procedure 
should result in an activation record being made on the stack
as for a `normal' (Estelle) procedure, as well as the transition
table of the process being pushed on a stack and replaced by the
transition table of the procedure.

Initially we may not implement SDL procedures. 
The use of a class library for the interpreter should make it
easy to add them later with minimal impact on the rest of the code.

\subsection{Transitions}

The {\tt start} transition in SDL corresponds to the initialisation
transition in Estelle.

The {\tt state} construct corresponds to an Estelle transition with a
{\tt FROM} and {\tt WHEN} clause (not present in the case of
continuous signals, where a {\tt PROVIDED} clause is used instead).

The SDL {\tt save} construct can be implemented by extending the
{\tt when} e-code instruction (which is like SDL's {\tt input})
to include a save set of signals as a parameter.

{\tt task} nodes correspond to Estelle assignment statements,
and {\tt output}, {\tt create}, {\tt call}, {\tt return},
{\tt stop}, {\tt set} and {\tt reset} nodes are dealt with as
described elsewhere in this section. 
SDL {\tt nextstate} nodes correspond to Estelle {\tt TO} clauses,
while SDL {\tt decisions} correspond to Estelle {\tt IF...THEN...ELSE}
constructs.

\subsection{Viewing and Importing}

{\tt view} and {\tt reveal} are used to communicate the value of
a variable between processes in the same block.
{\tt import} and {\tt export} are used to communicate the value
of a variable between processes in the same or different blocks.
These will be handled by implementing an {\tt import} instruction
which retrieves the value of the variable and pushes it on the stack
of the importing/viewing process.

\subsection{Signal Delivery}
\label{deliver}

When a signal is output in SDL, the signal identifier is mandatory,
with the path and destination process ID being optional. There
must exist at least one path that satisfies the constraints; if
there is more than one then one will be chosen.

During code generation we will build a table of all paths 
containing source process type, signal identifiers, the
delaying path (i.e. the channels along the path), and the
destination process type. 
Output statements will be matched against this information
to determine the destination process type ID.
A new e-code op, {\tt sdloutput}, which specifies a process type ID,
number of delaying channels, and optional process ID, will be 
generated, after the IDs of the channels have been pushed on
to the stack.

When interpreting this instruction, the delaying
channels IDs are popped off the stack, the delay computed, 
a message created and timestamped with its arrival time,
the target process identified (which could be any instance
of the type if the process ID is not specified), and the message
queued.

Each e-machine process will have an implicit interaction point
representing its input port. {\tt sdloutput} instructions will
deposit the signal on this IP queue.

\subsection{Saves}

Saves will be included in {\tt when} instructions, as noted
above.
This instruction will be extended to handle both timestamped
signals (i.e. SDL timers) and saves.

\subsection{Macros and Selections}

Macros and selections are not being implemented in the initial
version. 
Macro processing could be added later in a separate
front end. 
Selection processing is part of the tree rewriting
in mapping from $AS_0$ to $AS_1$, and could also be added
later without affecting the existing code.

\subsection{Signal Lists}

Signallists are used in saves, in valid input signal sets for
processes, and in the path part of channel and signalroute definitions.
These are simply used as shorthand, and correspond to signal sets in
Estelle.

\subsection{Storage Allocation and Addressing}

Before code can be generated, variables, parameters, etc,
must be allocated storage space on the stack and their addresses
noted.

\subsubsection{Field Addressing}

This is used to allocate addresses for fields within structures.
Fields are allocated offsets within the structure starting from zero.

\subsubsection{Variable Addressing}

Variables are allocated block scope levels as well as addresses.
Variable addresses are positive offsets from the stack frame base,
starting at offset 3 (the size of the stack frame).

\subsubsection{Parameter Addressing}

Parameters are allocated block scope levels as well as addresses.
Parameter addresses are negative offsets from the stack frame base,
starting from {\tt -LEN}, where {\tt LEN} is zero for procedures and
processes and the size of the return value for functions.

\subsubsection{Table Addressing}

This is done for interaction points and module variables in Estelle.
The address in this case corresponds to the index in the IP or modvar
table of the object. These would be contiguous except that IPs and
modvars can be arrays.

\section{Interaction with the Environment}

An SDL system interacts with the environment only through the
exchange of signals. 
The environment is assumed to know the system specification and
must comply with the constraints and requirements
given by it. 
It is assumed that there are processes in the environment that 
are in a position to send and receive signals to and from the system.
These processes must have unique addresses which are
different from the address of any process within the system.

Initially we will disallow systems from interacting with the
environment (this is much like the restriction in the {\em PEW} on
implicit and external modules and procedures).
A suitable honours or masters project in the future would be to
allow communication with the environment, implementing the dynamics 
of this communication by the semi-automatic generation of environment
processes that satisfy the communication constraints.

\section{Dynamic Semantics}

Although SDL is based on the concept of asynchronous communicating
extended finite-state machines, the dynamic model is described by
means of CSP meta-processes which communicate synchronously using events.

The static structure of a system describes which processes
communicate with which other processes, and the paths taken by
the signals used in the communication.
No delay is incurred by a signal when traversing a signal
route, but traversing a channel involves a nondeterministic delay
(SDL '92 allows this to be overridden).
The ordering of signals is preserved.

When a signal arrives at a process, it is placed in the process'
(single) input queue. 
This is a FIFO queue except when using the {\tt save}
construct or when setting/resetting timers.

\subsection{The Meta-Processes}

There are six types of meta-processes.
For each SDL process there is an {\em sdl-process} meta-process
and an {\em input-port} meta-process. 
For each communication path in the system there is a {\em path} process.
There is one instance each of the other three types, which model
the underlying system.
The meta-processes do not share data but interact by synchronous
message-passing. 
The processes are:

\begin{description}
\item [{\em system}] - this is the `main' meta-process, which
initialises the system and handles signal routing and the creation 
of {\em sdl-process}es;
\item [{\em path}] - these handle the non-deterministic channel
delays;
\item [{\em timer}] - this keeps track of the current time and 
handles time-outs. When an {\em sdl-process} uses the {\tt NOW} 
expression it will request {\em timer} for the time value. 
It is assumed that the environment sends a clock signal at regular
intervals to the {\em timer} (an implicit {\em tick-process});
\item [{\em view}] - this keeps track of all revealed variables.
Each time an {\em sdl-process} updates a revealed variable, it 
sends the new value to {\em view}. When a process is using the 
{\tt VIEW} expression, it will request the current value from {\tt
view};
\item [{\em sdl-process}] - these interpret the behaviour of
SDL-processes;
\item [{\em input-port}] - these handle the queueing of signals 
in SDL processes.
\end{description}

\subsection{Communication Domains}

The SDL model communication domains (that is, the CSP messages that
can be exchanged between the CSP pocesses) are summarised in
Table~\ref{CommDom}. 
A few comments are in order:

\begin{table}
\small
\begin{tabular}{|l|l|l|l|}
\hline
From & To & Message & Comment\\
\hline
{\em process} & {\em system} & {\tt
ProcessInitiated(InputPortID)}&
Sent after process creation\\
{\em process} & {\em system} & {\tt CreateInstanceReq(PId, Params)} & When doing a {\tt
create}\\
{\em system} & {\em process} & {\tt CreateInstanceAns( [PId] )} &
Reply after doing {\tt create}\\
{\em process} & {\em system} & {\tt SendSignal(SignalId, Args,
[PId], Via)} & When doing an {\tt output}\\
{\em process} & {\em system} & {\tt Stop()} & When doing an {\tt stop}\\
\hline
{\em process} & {\em port} & {\tt NextSignal(SaveSigIdSet)} & 
Fetch next signal from port\\
{\em port} & {\em process} & {\tt InputSignal(SignalId,
Args, Sender)} & Response to {\tt NextSignal}\\
{\em process} & {\em port} & {\tt SetTimer(TimerId,
Timeout, Args, Test)} & Set a timer\\
{\em process} & {\em port} & {\tt ResetTimer(TimerId, Args,
Test)} & Reset a timer\\
{\em process} & {\em port} & {\tt ActiveReq(TimerId, Args,
Test)} & Test if timer active\\
{\em port} & {\em process} & {\tt ActiveAns(Bool)} & 
Response to {\tt ActiveReq}\\
\hline
{\em process} & {\em view} & {\tt Reveal(VarId, Value, PId)} &
Update a revealed variable\\
{\em process} & {\em view} & {\tt ViewReq(VarId, PId)} & When
{\tt viewe}ing\\
{\em view} & {\em process} & {\tt ViewAns(Value)} & Response to
{\tt ViewReq}\\
\hline
{\em process} & {\em timer} & {\tt TimeReq()} &
When doing a {\tt now}\\
{\em timer} & {\em process} & {\tt TimeAns(Time)} &
Response to {\tt TimeRequest}\\
{\em port} & {\em timer} & {\tt TimeReq()} &
When doing a {\tt now}\\
{\em timer} & {\em port} & {\tt TimeAns(Time)} &
Response to {\tt TimeRequest}\\
\hline
{\em environ} & {\em system} & {\tt CreatePID(Port)} &
Environment process created\\
{\em system} & {\em environ} & {\tt PIdCreated(PId)} & 
Acknowledgment of {\tt CreatePId}\\
{\em environ} & {\em system} & {\tt ReleasePId(PId)} &
Environment process killed\\
\hline
{\em system} & {\em view} & {\tt Die(PId)} & When killing a process\\
\hline
{\em system} & {\em path} & {\tt QueueSignal(SignalId, Args,
PId, Port)} & When doing an {\tt output}\\
{\em system} & {\em path} & {\tt DiscardSignals(Port)} & When killing
a process\\
\hline
{\em system} & {\em port} & {\tt Delivered(SignalId, Args,
SenderPId)} & Signal delivery\\
{\em path} & {\em port} & {\tt Delivered(SignalId, Args,
SenderPId)} & Signal delivery\\
\hline
{\em system} & {\em port} & {\tt StopQueue()} & When killing a
process\\
\hline
{\em timer} & {\em tick} & {\tt Time()} & Models time\\
\hline
\end{tabular}
\label{CommDom}
\caption{SDL Model Communication Domains}
\end{table}

When a process interprets a {\tt create} request, it sends a {\tt
CreateInstanceReq} to {\em system}, containing the process
identifier of the process to be started and the actual parameters.
{\em system} responds by outputting {\tt CreateInstanceAns} with
the PId-Value of the started process, or {\tt nil} if no process
could be started.

When a process interprets an {\tt output} request, it sends a {\tt
SendSignal} to {\em system} with the signal identifier, optional
argument values, optional destination process instance, and optional
via set of channel IDs or signal route IDs.

Note that the variable value in {\tt Reveal} and {\tt ViewAns}
can be {\tt UNDEFINED}.
A {\tt Reveal} message carries the PId of {\tt self}, while a
{\tt ViewReq} carries the PId of the instance that reveals the variable.

An SDL process sends a {\tt TimeReq} when interpreting a {\tt now}
expression. 
An input port continually tests on the expiration of its
timers, so it also sends {\tt TimeReq}.

A {\tt Die} message informs the view process that it can delete any
revealed variable entries for the process.

\subsection{The {\em Entity-dict} Domain}

The information required to interpret an SDL system is stored in
the entity dictionaries. Each {\em sdl-process} has its own version of
{\em Entity-Dict}, containing:

\begin{itemize}
\item the type values of the {\em sdl-process};
\item the CSP process ID values of the {\em input-port}, the parent process,
and the {\em sdl-process} itself;
\item identifiers for the literals {\tt TRUEVALUE}, {\tt FALSEVALUE}
and {\tt NULLVALUE};
\item the qualifier denoting the current scopeunit;
\item a function used by the {\em timer} processor to test if a timer
has expired;
\item the reachabilities leading to/originating from the environment;
\item an identifier map.
\end{itemize}

The identifier map maps identifiers and their associated entity class
(namely {\tt SIGNAL}, {\tt PROCEDURE}, {\tt TYPE}, {\tt SORT}, {\tt PROCESS}
or {\tt VALUE}) into descriptors.
The following descriptors exist:

\begin{itemize}
\item {\em signal descriptors} contain the list of sort or syntype
identifiers attached to the signal (shown as {\tt \{ sortl \}});
\item {\em procedure descriptors} contain the list of formal parameter
descriptors (variable identifiers and whether the parameters are
value or reference parameters), and the procedure graph
(shown as {\tt \{ formparms, graph \}});
\item {\em type descriptors} and {\em sort descriptors} contain
information specific to SDL's data typing;
\item {\em process descriptors} contain the parameter list, the
initial and maximum number of processes, the process graph, and the
reachability set. A reachability defines a process ID which may be
reached from this process in sending a signal from a signal
identifier set using a certain path (namely, a list of signalroute
and channel identifiers). We show this as
{\tt \{ parm, init, maxi, graph, inrset \} };
\item {\em variable descriptors} contain the variable identifier, the
sort or syntype identifier, whether the variable is revealed or not,
and an optional reference to storage
(shown as {\tt \{ vid, sid, revealed, stg \}});
\item {\em operator descriptors} contain the list of sorts or
syntypes of the arguments and result (shown as 
{\tt \{ sortlist, sort \}});
\end{itemize}

\subsection{The {\em system} Processor}

We now give pseudo-code algorithms for the various CSP processors
starting with the {\em system} processor. 
In the pseudo-code we represent the sending of a CSP message by {\tt <=}
and the receiving of a message by {\tt =>}.

\begin{verbatim}
/* Interpret the SDL system */

system(SysDef AST1tree, BlockIDSet subset, AuxInf auxinf)
begin
    create the instance map, queue map, path map, and entity-dict
    trap errors
    View = start view()
    Timer = start timer()
    start-initial-processes(entity-dict)
    pathd(delayf)
    handle-inputs(entity-dict)
end
\end{verbatim}

The {\em system} process is the initial CSP process which creates 
the other processes. 
At the top level, it initialises the various
map tables and the top level entity dictionary, starts the {\em view}
process and {\em timer} process, creates the initial {\em
sdl-process}es, creates {\em path} processes for each communication
path, and then enters a loop waiting for messages from other CSP
processes.

In our case, the place of the {\em system} process is taken by the
{\em PEW} scheduler, which also manages {\em view}, {\em timer}
and {\em pathd} requests.

To start the initial processes, we generate an initialisation
transition for each process which creates all initial child processes
(this effectively recurses through the process tree until all initial
processes have been made).

\begin{verbatim}
/* Start sdl-processes */

start-initial-processes(EntityDict entity-dict)
begin
    for each PId p in dict[ {PROCESS, *} ]
        loop (initial number) times
            handle-create-instance-request(p,nil,nil)
end
\end{verbatim}

{\tt start-initial-processes} is straightforward and is handled
by the initialisation transitions mentioned above.

\begin{verbatim}
/* Start a path processor instance for each pair of
   Process-identifier and path in the system. Updates
   a map from paths to processor instances */

pathd(BoolFn delayf)
begin
    let rs = reachability set of processes in environment
    for all reach in rs do
    begin
        let p = reach except last (signal route) component
        if (p not in pathmap)
        begin
            cspp = start path(delayf)
            make entry pathmap[p] = { cspp }
        end
    end
    for all pd: process in entitydict do
    begin
        for all reach in reachability set of pd do
        begin
            let p = reach except first and last (signal route) components
            if (p not empty and p not in pathmap)
            begin
                cspp = start path(delayf)
                make entry pathmap[p] = { cspp }
            end
        end
    end
end
\end{verbatim}

As we do not allow processes in the environment to begin with, we
need only be concerned with the second half of this routine as the
set of processes in the environment is empty.

We do not actually create such processes, but we build a table
similar to the {\tt pathmap} so that we can handle the {\tt
sdloutput} e-code instruction.

\begin{verbatim}
/* Handle all communication of system after initialisation */

handle-inputs(EntityDict entity-dict)
begin
    begin cycle until error
        when sender => SendSignal(si,vl,r,p)
          handle-send-signal(si,vl,r,p, sender)
        when sender => CreateInstanceReq(id, vl)
          handle-create-instance-request(id, vl, sender)
        when sender => Stop
          handle-stop(sender)
        when sender => CreatePId(port)
          handle-create-from-env(port, sender)
        when sender => ReleasePId(p)
          handle-stops-in-env(p, sender)
    end cycle
end
\end{verbatim}

This is the main processing loop of the system.

\begin{verbatim}
/* Handle stop of "processes" in the environment
   by updating maps within the system.
*/

handle-stops-in-env(PIdValue p, CSPId sender)
begin
    let q = get-input-port(p)
    remove instancemap[sender]
    remove queuemap[q]
    discard-signals-to-port(q)
end

/* Handle the creation of PId-Values in the environment.
   Update maps within the system, and return the PId-Value
   to the environment.
*/

handle-create-from-env(CSPId port, CSPId sender)
begin
    let { pid, pidclass } = getpid(entitydict)
    make entry instancemap[sender] = { ENV, pid }
    make entry queuemap[pidclass] = { port }
    sender <= PIdCreated(pid)
end
\end{verbatim}

The above two routines are only required for processes that exist
outside of the system in the environment. As we currently disallow
such processes there is nothing to be done here.

\begin{verbatim}
/* Route signals */

handle-send-signal(SignalID si, ValList vl, PIdValue r,
        DirectVia p, CSPId sender)
begin
    get { sid, sp } from instancemap[sender]
    if (sid is an identifier)
        let re = reachability set of process sid
    else
        let re = reachability set of environment
    let re' be those reachabilities in re that can carry si
    let re" be those reachabilities in re' that satisfy vl
    let rp be the set of potential receivers
    if there is not exactly one receiver, run-time error
    let {rident, ri } = { receiver's process ID and PIdValue }
    let path = a path leading to the receiver (may be choice)
    let rcsp = queuemap[get-input-port(receiver)]
    let reduced-path = delaying-path(path, sid, rident)
    if the reduced path is not empty
    then pathmap[reduced-path] <= QueueSignal(si, vl, sp, rcsp)
    else rcsp <= Delivered(si, vl, sp)
end
\end{verbatim}

This routine identifies the receiving process of a signal, which must
be unique, and chooses the path the signal will traverse (this may
not be unique). The path is reduced to a delaying path (namely, the
set of channels traversed). If no channels are traversed (i.e. signal 
is between processes in same block) then the signal is placed in the
receiver's input port immediately; otherwise it is queued by the path
processor for the chosen path, whose task is to introduce a delay
before delivery.

\begin{verbatim}
/* Reduce the communication path to the delaying path */

Path delaying-path(Path path, ProcessID sender, ProcessID receiver)
begin
    if path is empty or a single signal route ID
        then return it unmodified
    else if sender is ENVIRONMENT
        then remove the signal route ending the path
    else if receiver is ENVIRONMENT
        then remove the signal route ID starting the path
    else remove the start and end signal route IDs
    return the resulting path
end
\end{verbatim}

Signal routes incur no delay; the above routine just removes them
from the signal path. The result is either empty or a set of
channels.

\begin{verbatim}
/* Get an unused PId-Value and the equivalence class it belongs to */

{ PIDValue PIDValueSet } getpid(EntityDict entitydict)
begin
    let pid be a new, unique PId
    let class be the equivalence class of pid
    return { pid, class }
end

/* Handle creation of sdl-processes */

handle-create-instance-request(ProcessID PId, ValList Params, CSPId Parent)
begin
    if (max number not exceeded)
    then begin
        let { NewPId, PIDClass } = getpid(entitydict)
        let p = start sdl-process(Parent, NewPId, Params, PId)
        p => ProcessInitiated(qcsppid)
        make entry processmap[p] = { PId, NewPId }
        make entry queuemap[PIDClass] = { qcsppid }
        increment number of instances of type PId
    end
    else NewPId = nil
    if (Parent not nil)
        Parent <= CreateInstanceAns(NewPId)
end
\end{verbatim}

This is straightforward, and just administers the creation of new SDL
processes, updating the {\tt processmap} and {\tt queuemap}
appropriately. The equivalence class of a type is the set of all terms
of that type. In the case of processes, there is a set of equivalence
classes for each process type. Each equivalence class contains a 
process ID. Thus the {\tt PIDClass} is simply a set containing 
only the new {\tt PId}.

\begin{verbatim}
/* Handle STOP nodes */

handle-stop(CSPId sender)
begin
    get { prid, p} from instancemap[sender]
    let q = get-input-port(p)
    remove instancemap[sender]
    remove queuemap[q]
    decrement the count of number of instances of prid
    discard-signals-to-port(q)
    q <= StopQueue()
    View <= Die(p)
end
\end{verbatim}

In this case {\tt prid} is the SDL process type identifier and {\tt
p} is the CSP process ID. 
The entry for the process is removed from
the instance map, and the entry for its port is removed from the
queuemap.
The count of the number of processes of the type are
decremented, any signals destined for the process's associated port
are removed from the {\em path}s, the {\em port} process is
terminated, and any viewed variables belonging to the process
instance are removed from the view map.

\begin{verbatim}
/* Output to all path instances telling them to delete signal
   instances wainting to be transmitted to one input port.
*/

discard-signals-to-port(Port q)
begin
    for all p : paths in the pathmap
        p <= DiscardSignals(q)
end
\end{verbatim}

This routine is called when an {\em sdl-process} terminates, to
remove any signals queued by {\em path} processes that are associated
with the {\em sdl-process}.
A {\tt DiscardSignals} message is sent to
each path, which will only handle the message if the destination port
of the path is the same as {\tt q}. Messages that are already
delivered to input port processes are not removed.

\begin{verbatim}
/* Delay function for delaying paths */

delayf()
begin
    return random boolean value
end
\end{verbatim}

This function just provides for nondeterministic delays in {\em path}
processes.

\subsection{The {\em View} Processor}
\label{viewproc}

This processor interprets {\tt VIEW} and {\tt REVEAL}.

\begin{verbatim}
view()
begin
    create an empty viewmap
    begin cycle until error
        when (sdl-process => Reveal(id, value, pid))
            viewmap[pid, id] = value
        when (viewpid => ViewReq(id, revealpid) )
        begin
            if entry viewmap[revealpid, id] exists
                then viewpid <= ViewAns(viewmap[revealpid, id])
            else run-time error
        end
        when (system => Die(pid) )
            delete all viewmap[pid, *] entries
    end cycle
end
\end{verbatim}

To implement the view processor, the scheduler must have some
means of determining the value of a revealed variable (i.e.
to play the role of the {\tt viewmap} in the formal semantics).
This should be possible simply by examining the AST, and
locating the process ID and stack address of the variable.

For each {\tt VIEW} expression, an {\tt import} e-code
instruction is generated (this is a new e-code instruction).
The interpreter performs the instruction by obtaining the
current value of the revealed variable and pushing it on to
the stack.

If the value lookup can be done using the AST rather than a new
table, the {\tt viewmap} is implicit, and thus no {\tt Die}
processing is necessary.
An alternative approach is to add another e-code instruction,
namely {\tt export}, and make the value communication explicit.
Whenever a {\tt REVEAL}ed variable is assigned to, an {\tt export}
instruction is output to inform the scheduler that the
variable's value has changed.

\subsection{The {\em Path} Processor}

\begin{verbatim}
path(BoolFunc delayf)
begin
    let pqueue = a path queue of entries {SignalId, ValueLst, PIdVal, Port}
    begin cycle until error
        when system => QueueSignal(si, vl, sp, rcsp)
            append { si, vl, sp, rcsp } to pqueue
        when system => DiscardSignals(q)
            remove all { *,*,*,q } entries in pqueue
        when delayf() and pqueue nonempty
        begin
            let p = front entry of pqueue
            p.Port <= Delivered(p.SignalId, p.ValueLst, p.PIdVal)
            remove p from pqueue
        end
    end cycle
end
\end{verbatim}

The {\em path} processor handles the queueing of signals for a
process.
It effectively is just a delaying queue.
When the system  queues a signal, it is appended to the queue
maintained by the corresponding {\em path} process.
After some nondeterministic delay the message at the front of the
queue is removed and delivered to the destination 
{\em sdl-process}' associated {\em input-port} process.

If an {\em sdl-process} dies, the {\em system} sends a {\tt
DiscardSignals} message to the {\em path}, which removes any signals
destined for the specified port. 

In the {\em PEW}, equivalent behaviour can be obtained by
timestamping each message with a non-deterministic `holding time'
before placing it on the input queue associated with a process.
Messages will not be able to be removed from the queue until their
holding time has elapsed (they will effectively be regarded as `not
present' until this occurs). 
When an Estelle process terminates, its message queues are destroyed,
so {\tt DiscardSignals} handling is implicit in the {\tt PEW}.

\subsection{The {\em Input-Port} Processor}

This processor handles signal queueing for a process, as well as
timer sets/resets and expiry.

\begin{verbatim}
/* Interpret the input-port of sdl-process */

input-port(PIdVal ppid, IsExpired expiredf)
begin
    let queue = a new, empty queue of entries {SignalId, ValueLst, PIdVal}
    let waiting = false
    let timers = a map from {TimerId ArgList} to { CSPId Value EquivTst }
    let pendingset be a set of SignalIds
    begin cycle until error
        when p => Delivered(sid,vl,se)
            handle-queue-insert(sid, vl, se, p)
        when p => NextSignal(saveset)
            handle-queue-extract(saveset, <>, queue, p)
        when p => StopQueue
            stop
        when p => SetTimer(tid, v, al, et)
            handle-set-timer(tid, v, al, et, p)
        when p => ResetTimer(tid, al, et)
            handle-reset-timer(tid, al, et)
        when p => ActiveReq(tid, al, et)
            handle-active-request(tid, al, et, p)
        timer <= TimeReq()
        handle-time-request(ppid, expiredf)
    end cycle
end
\end{verbatim}

\begin{verbatim}
/* Insert a signal in the queue */

handle-queue-insert(SignalId sid, ValList vl, PIdVal sender, CSPId pcsp)
begin
    append signal { sid, vl, sender } to queue
    if not waiting 
        then handle-queue-extract(pendingset, <>, queue, pcsp)
end
\end{verbatim}

\begin{verbatim}
/* Extract one element from the queue and send it to
   sdl-process if the latter is ready to receive input */

handle-queue-extract(SignalIdSet saveset, Queue qf, Queue qa, CSPId pcsp)
begin
    if (qa nonempty) then
    begin
        let s = head of qa
        get { sid, vl, se } from s
        if (sid in saveset)
        then handle-queue-extract(saveset, qf+<s>, tail qa, pcsp)
        else begin
            pcsp <= Input-Signal(sid, vl, se)
            queue = concatenation of qf and tail qa
            waiting = false
            if (sid is a TimerId)
            then begin
                if there is an {a, et} such that { sid, a} is in the
                     timers domain, and same-argument-values(a, vl, et)
                     (where et is the equiv test of timer {sid, a} )
                then remove the {sid, a} entry from the timers domain
            end
        end
    end 
    else begin
        pendingset = saveset
        waiting = true
    end
end
\end{verbatim}

This recurses through the input port queue looking for the first
signal not in the save set. The signal is removed from the queue and
sent to the sdl-process for handling. If the signal is a timer, it is
removed from the timers map.

\begin{verbatim}
/* Test whether two lists of Terms are equivalent, as
   defined by the equivalence test et */

Bool same-argument-values(ArgList a, ArgList vl, EquivTest et)
begin
    if (length(a) = length(vl))
        then if et(a[i],vl[i]) for all i = 1,...,length(a)
            return true
    return false
end
\end{verbatim}

\begin{verbatim}
/* Set a timer by updating the timers map */

handle-set-timer(TimerId tid, Value v, ArgList al, EquivTst et, CSPId p)
begin
    handle-reset-timer(tid, al, et)
    make entry timers[{tid, al}] = {p, v, et}
end
\end{verbatim}

This resets the timer (in case it is already set or has expired and
is queued), and makes an entry in the map.

\begin{verbatim}
/* reset a timer by updating the timers map and the queue */

handle-reset-timer(TimerId tid, ArgList al, EquivTst et)
begin
    for all entries {t, a} in timers do
    begin
        if t = tid and same-argument-values(a, al, et)
        then begin
            let e be the expiration time of the entry
            remove entry timers[{t, a}]
            if (e = nil)
            then handle-remove-timer-from-queue(tid, al, et, <>, queue)
        end
    end
end
\end{verbatim}

This removes a timer entry from the timers map, and if necessary,
from the input port queue.

\begin{verbatim}
/* Remove one element from the queue */

handle-remove-timer-from-queue(SignalId sid, Arglist al, EquivTst et,
                    Queue qf, Queue qa)
begin
    get { si, vl } from head of qa
    if (si = sid and same-argument-values(vl, al, et))
    then queue = concatenation of qf and tail(qa)
    else handle-remove-timer-from-queue(sid, al, et, qf+<head(qa)>, tail(qa))
end
\end{verbatim}

This recursively searches the queue for the specified timer
instance and removes it from the queue.

\begin{verbatim}
/* Supply the answer to ACTIVE based on the timers map */

handle-active-request(TimerId tid, Arglist al, EquivTst et, CSPId pcsp)
begin
    if there is a timer entry { tid, a } such that 
        same-argument-values(al, a, et) then stat = true
    else stat = false
    pcsp <= ActiveAnswer(stat)
end
\end{verbatim}

Note that timers that have expired and are in the input port queue
are considered active until they are consumed.

\begin{verbatim}
/* Handle the comparison with the actual time for all timers being
   set */

handle-time-request(Value ppid, IsExpired expiredf)
begin
    when timer => TimeAnswer(t)
    begin
        for all entries {tid, al} in timers do
        begin
            get {p, expt, et} from timers[{tid, al}]
            if (expt not nil and expiredf(expt,t))
            then begin
                set timers[{tid, al}] = {p, nil, et}
                handle-queue-insert(tid, al, ppid, p)
            end
        end
    end
end
\end{verbatim}

This routine checks if any timers have expired, and if so, queues
them on the input port queue, after updating the {\tt timers} map
to indicate that the timer is `on the queue'.

\subsection{The {\em Timer} Processor}

\begin{verbatim}
/* Interpret the timer handling in the underlying system */

timer(TimeInfo timeinf)
begin
    get { timef, startt } from timeinf
    let timenow = startt
    begin cycle
        if (tick => Time()) then timenow = timef(timenow)
        if (p => TimeReq()) then p <= TimeAns(timenow)
    end cycle
end
\end{verbatim}

Thsi routine handles the system time. It responds to requests for the
time from port processes, and updates the system time using the
external function {\tt timef} whenever the{\tt tick} processor sends
it a timer tick message.

\subsection{The Informal {\em tick} Processor}

\begin{verbatim}
tick()
begin
    begin cycle
        timer <= Time()
    end cycle
end
\end{verbatim}

This models informally the interval between consecutive ticks.

\subsection{The {\em sdl-process} Processor}

\begin{verbatim}
/* Interpret an SDL process */

sdl-process(PIdVal parentp, PIdVal selfp, ValList actparml, 
            ProcessId process-id)
begin
    make Identifier{qual,nm} from process-id
    let dict1 = dict
    set dict1[SCOPEUNIT] = qual + ProcessQualifier(nm)
    set dict1[PORT] = start input-port(selfp, dict[EXPIREDF]);
    set dict1[SELF] = selfp;
    if parentp = nil then set dict1[PARENT] = null
    else set dict1[PARENT] = parentp
    let sender = null
    let offspring = null
    let stg = new empty storage map between identifiers and values
    trap exits with run-time error
    trap STOP with system <= Stop()
    get {formparml,,,graph} from dict1[{process-id, PROCESS}]
    let dict2 = dict1
    for each local variable and formal parameter
        modify dict2 to refer to stg
    init-process-decls(dict2)
    init-process-parms(formparml, actparml)(dict2)
    system <= ProcessInitiated(dict2[PORT])
    int-process-graph(graph)(dict2)
end
\end{verbatim}

This is the top-level routine for new instances of {\em sdl-process}.
The entity dictionary is modified so that {\tt SCOPEUNIT}, {\tt
PORT}, {\tt SELF} and {\tt PARENT} refer to the new process 
(a {\em port} process is created to do this), and each
local variable and parameter is allocated storage. 
The local variables and formal parameters are initialised to their initial values
(which may be {\tt UNDEFINED}). 
The {\em system} is then informed
that the process has been created with the associated port, 
and the initial transition is executed.

Modifications needed by the {\em PEW} are for the support of the
special {\tt UNDEFINED} value. The initialisation of local variables
and parameters can be done by generating assignment instructions
at the start of the initial transition.

\begin{verbatim}
/* Update the storage with the variable declarations associated
   with the sdl-process being interpreted */

init-process-decls(EntityDict dict)
begin
    for all entries {id, VALUE} in dict do
        if is-Var(dict[{id, VALUE}] and sQualifier(id)=dict[SCOPEUNIT]
            then update-stg(id, nil)
end
\end{verbatim}

\begin{verbatim}
/* Update the local process storage with formal process parameters
   and the optionally applied actual parameters */

init-process-parms(ParamDomainList formparml, ValueList actparml)
begin
    for all i = 1,...,length(formparml) do
        update-stg(formparml[i], actparml[i])
end
\end{verbatim}

\begin{verbatim}
/* Interpret an SDL process graph */

int-process-graph(ProcessGraph graph)
begin
    get { trans, stateset } from graph
    trap all exit(state-name) from int-state-node and int-transition
        by interpreting the associated state node
    get {nodel, termordec } from trans
    int-transition(nodel, termordec)
end
\end{verbatim}

This executes the initialisation transition of the process, after
making sure that any exits that have a state name argument cause the
associated state to be interpreted. This is the mechanism used to
implement the {\tt NEXTSTATE} construct.

\begin{verbatim}
/* Request a new signal from the input-port and interpret the
   corresponding transition */

int-state-node(StateNode { , SaveSigSet(saveset), inputset} )
begin
    when dict[PORT] => InputSignal(sid, actparml, sender')
    begin
        sender = sender'
        let { inpnode } = input node in inputset with SignalId sid
        get { , formparml, trans } from inpnode
        for all i = 1, ..., length(formparml)
        do begin
            if (formparml[i] not nil)
            then update-stg(formparml, actparml[i])
        end
        get {nodel, termordec } from trans
        int-transition(nodel, termordec)
    end
end
\end{verbatim}

This gets an input signal, initialises the actual arguments in the 
input with the argument values conveyed by the signal, and
interprets the associated transition.

\begin{verbatim}
/* Interpret a transition */

int-transition(GraphNodeLst nodel, TermOrDecNode termordec)
begin
    if (nodel empty)
    then begin
        if (termordec is NextstateNode(nm)) then exit(nm)
        else if (termordec is StopNode()) then exit(STOP)
        else if (termordec is ReturnNode()) then exit(RETURN)
        else if (termordec is DecisionNode(,,))
            then int-decision-node(termordec)
    end else begin
        int-graph-node(head(nodel))
        int-transition(tail(nodel), termordec)
    end
end
\end{verbatim}

If the node list is empty, the terminator is interpreted, otherwise
the head node is interpreted and we recurse to interpret the
remaining nodes.

\begin{verbatim}
/* Interpret a decision node */

int-decision-node(DecisionNode {quest, answset, alseansw} )
begin
    let answset' = answers in answset matching quest
    if (answset not empty)
    then begin
        get { ,trans} from answset
        get {nodel, termordec} from trans
        int-transition(nodel, termordec)
    end 
    else if elseansw not nil
    then begin
        get {trans} from elseansw
        get {nodel, termordec} from trans
        int-transition(nodel, termordec)
    end
end
\end{verbatim}

The set of matching answers is extracted. Answers may not overlap
(static semantics) so {\tt answset'} must be empty or contain a
single answer. In the latter case, the associated transition is
interpreted; in the former case, the else part, if present, is
interpreted.

\begin{verbatim}
/* Interpret a graph node */

int-graph-node(GraphNode graphnode)
begin
    if (graphnode is TaskNode(silt))
        then int-task-node(silt)
    else if (graphnode is OutputNode(,,,))
        then int-output-node(graphnode)
    else if (graphnode is CreateReqNode(,))
        then int-create-node(graphnode)
    else if (graphnode is CallNode(,))
        then int-call-node(graphnode)
    else if (graphnode is SetNode(,,))
        then int-set-node(graphnode)
    else if (graphnode is ResetNode(,))
        then int-reset-node(graphnode)
end
\end{verbatim}

This calls a handler appropriate to the type of node being
interpreted.

\begin{verbatim}
/* Interpret a TASK node */

int-task-node(Assignment silt)
begin
    int-assign-stmt(silt)
end
\end{verbatim}

A task is simply an assignment.

\begin{verbatim}
/* Interpret a SET node */

int-set-node(SetNode {texp, tid, exprl})
begin
    let val = eval-expression(texp)
    get { sortl } from dict[ {tid, SIGNAL } ]
    for i = 1,...,length(exprl)
    begin
	    let vall[i] = eval-expression(exprl[i])
	    let vall'[i] = reduce-term(sortl[i], vall[i], dict[SCOPEUNIT])
    end
    define f(t1,t2) = is-equivalent(t1, t2, dict[SCOPEUNIT])
    let fail = false
    for i = 1,...,length(vall)
    begin
        if not (range-check(sortl[i], vall'[i]))
        then fail = true
    end
    if (fail) then exit("syntype range error")
    else dict[PORT] <= SetTimer(tid, val, vall', f)
end
\end{verbatim}

The timer expression and list of actual parameters is evaluated,
an {\tt isequivalent} function is created to be used by the input
port process to test whether this timer is already set with the same
set of parameters, the parameters are checked for range violations,
and the port process is instructed to set the timer.

\begin{verbatim}
/* Interpret a RESET node */

int-reset-node(ResetNode {tid, exprl})
begin
    get { sortl } from dict[ {tid, SIGNAL } ]
    for i = 1,...,length(exprl)
    begin
	    let vall[i] = eval-expression(exprl[i])
	    let vall'[i] = reduce-term(sortl[i], vall[i], dict[SCOPEUNIT])
    end
    define f(t1,t2) = is-equivalent(t1, t2, dict[SCOPEUNIT])
    let fail = false
    for i = 1,...,length(vall)
    begin
        if not (range-check(sortl[i], vall'[i]))
        then fail = true
    end
    if (fail) then exit("syntype range error")
    else dict[PORT] <= ResetTimer(tid, vall', f)
end
\end{verbatim}

The timer expression and list of actual parameters is evaluated,
an {\tt isequivalent} function is created to be used by the input
port process to test whether this timer is already set with the same
set of parameters, the parameters are checked for range violations,
and the port process is instructed to reset the timer.

\begin{verbatim}
/* Assign a variable the value of an expression */

int-assign-stmt(Assignment {vid, exp})
begin
    let val = eval-expression(exp)
    update-stg(vid,val)
end
\end{verbatim}

The expression is evaluated and assigned to the variable.

\begin{verbatim}
/* Interpret an OUTPUT node */

int-output-node(OutputNode {sid, exprl, dest, via})
begin
    let pidval = eval-expression(dest)
    get { sortl } from dict[ {tid, SIGNAL } ];
    for i = 1,...,length(exprl)
    begin
	    let vall[i] = eval-expression(exprl[i])
	    let vall'[i] = reduce-term(sortl[i], vall[i], dict[SCOPEUNIT])
    end
    let fail = false
    for i = 1,...,length(vall')
    begin
        if not (range-check(sortl[i], vall'[i]))
        then fail = true
    end
    if (fail) then exit("syntype range error")
    else system <= SendSignal(sid, vall', pidval, via)
end
\end{verbatim}

The PId and actual parameters are evaluated, and the parameters
range-checked, after which the system processor is instructed to
handle the signal.

\begin{verbatim}
/* Interpret a CREATE node */

int-create-node(CreateNode {pid, exprl})
begin
    get { formparms,,,,} from dict[ {pid, PROCESS} ]
    get { sortl } from the sorts of the values in formparms
    for i = 1,...,length(exprl)
    begin
	    let vall[i] = eval-expression(exprl[i])
	    let vall'[i] = reduce-term(sortl[i], vall[i], dict[SCOPEUNIT])
    end
    system <= CreateInstanceReq(pid, vall')
    when system => CreateInstanceAns(offspring')
    begin
        if offspring' is nil
        then offspring = null
        else offspring = offspring'
    end
end
\end{verbatim}

The actual parameters are evaluated, and the system processor is
instructed to created the process. The {\t offspring} variable is set
to the process ID of the new process, or {\tt NULL} if the process
could not be created.

\begin{verbatim}
/* Interpret a procedure call */

int-call-node(CallNode {prd-id, exprl})
begin
    let newstg = a new empty storage map
    get { formparms, graph } from dict[ {prd-id, PROCEDURE} ]
    get {qual, num} from prd-id
    let newlevel = qual + PROCEDURE + nm
    let decl-parm-set be the set of variables and parameters for newlevel
    let dict1 = establ-dyn-dict(formparms, exprl, newstg, decl-parm-set)
    let dict2 = dict1
    dict2[SCOPEUNIT] = newlevel
    trap exit(RETURN)
    int-procedure-graph(graph)(dict2)
end
\end{verbatim}

A storage area for the procedure is created, the formal parameters
and procedure graph retrieved, the scope level computed, a new
dictionary is created with the formal parameters and local variables
added (and these are allocated addresses in the storage area), and
the procedure graph is interpreted until a {\tt RETURN}.

\begin{verbatim}
/* Interpret a procedure graph */

int-procedure-graph(ProcedureGraph graph)
begin
    get { {trans }, stateset} from graph
    trap exit(statenm) with int-state-node(node with name statenm)
    get { nodel, termordec } from trans
    int-transition(nodel, termordec)
end
\end{verbatim}

The graph is partitioned into a start transition and set of states,
all exits that have state names as arguments are trapped by
interpreting the associated state node, and the start transition is
interpreted.

\subsection{Expressions}

\begin{verbatim}
Value eval-expression(Expression exp)
begin
    if exp is nil 
        then return nil
    else if exp is Identifier(,)
        then return eval-variable-identifier(exp)
    else if exp is GroundExpression()
        then return eval-ground-expression(exp)
    else if exp is OperatorApplication(,)
        then return eval-operator-application(exp)
    else if exp is ConditionalExpression(e1,e2,e3)
        then return eval-conditional-expression(e1,e2,e3)
    else if exp is ViewExpression(,)
        then return eval-view-expression(exp)
    else if exp is TimerActiveExpression(,)
        then return eval-active-expression(exp)
    else if exp is NowExpression()
        then return eval-now-expression()
    else if exp is SelfExpression()
        then return dict[SELF]
    else if exp is ParentExpression()
        then return dict[PARENT]
    else if exp is OffspringExpression()
        then return offspring
    else if exp is SenderExpression()
        then return sender
end
\end{verbatim}

\begin{verbatim}
Value eval-variable-identifier(Identifier id)
begin
    get { vid,,,stg } from dict[ {id, VALUE} ]
    if stg[vid] is UNDEFINED
    then exit("Value is undefined")
    else return stg[vid]
end
\end{verbatim}

\begin{verbatim}
Value eval-ground-expression(exp)
begin
    if exp is an identifier then return exp
    if exp is a conditional term { bex, ex1, ex2 } 
    then eval-conditional-expression(bex, ex1, ex2)
    else begin
        /* must be an operator application */
        get { opid, arglist } from exp
        get {sortlist, sort} from dict[ {opid, VALUE} ]
        if all rangecheck(sortlisti], arglist[i]) are OK
        then begin
            let arglist'[i] = eval-expression(arglist[i]) for all i
            let t = ground term resulting from applying opid to arglist'
            if rangecheck(sort, t) is ok then return t
            else exit("Value out of syntype range")
        end 
        else exit("Value out of syntype range")
    end
end
\end{verbatim}

\begin{verbatim}
Value eval-operator-application( {opid, expl} )
begin
    get {sortl, result } from dict[ {opid, VALUE} ]
    for i = 1,...,length(expl)
    begin
        let vall[i] = eval-expression(expl[i])
        do range-check)sortl[i], vall[i])
    end
    if a range check failed then exit("Value out of syntype range")
    let term = the ground term resulting from applying opid to vall
    do a range check on the result
    if a range check failed then exit("Value out of syntype range")
    else return term    
end
\end{verbatim}

\begin{verbatim}
Value eval-conditional-expression(exp1, exp2, exp3)
begin
    if is-equivalent(eval-expression(exp1), true, dict[SCOPEUNIT])
    then return eval-expression(exp2)
    else if is-equivalent(eval-expression(exp1), false, dict[SCOPEUNIT])
    then return eval-expression(exp3)
    else exit("Condition must be true or false")
end
\end{verbatim}

\begin{verbatim}
Value eval-view-expression( {id, exp} )
begin
    let pid = eval-expression(exp)
    let pid' = reduce-term(dict[PIDSORT], pid, dict[SCOPEUNIT])
    view <= ViewReq(id, pid')
    when view => ViewAns(val)
    begin
        if val is UNDEFINED
        then exit("Viewed value is undefined")
        else return val
    end
end
\end{verbatim}

\begin{verbatim}
Value eval-active-expression( {timer,exprl} )
begin
    get { qual, } from timer
    get sortl from dict[ {timer, SIGNAL} ]
    for i = 1,...,length(expl)
    begin
        let vall[i] = eval-expression(exprl[i])
        let vall'[i] = reduce-term(sortl[i], vall[i], dict[SCOPEUNIT])
    end
    define f(t1,t2) = is-equivalent(t1, t2, qual)
    dict[PORT] <= ActiveReq(timer, vall', f)
    when dict[PORT] => ActiveAns(b)
        if b then return true else return false
end
\end{verbatim}

\begin{verbatim}
Value eval-now-expression()
begin
    timer <= TimeReq()
    when timer => TimeAns(val) return val
end
\end{verbatim}

\begin{verbatim}
update-stg(Identifier id, Value val)
begin
    get {vid, sid, revealed, stg' } from dict[ {id, VALUE} ]
    if val is nil let val' be UNDEFINED
    else let val' = reduce-term(sid, val, dict[SCOPEUNIT])
    if range-check(sid, val') is ok
    then begin
        make entry stg'[vid] = val'
        if revealed then view <= Reveal(vid, val', dict(SELF))
    end
    else exit("Value not in syntype range")
end
\end{verbatim}

\begin{verbatim}
Bool range-check(SortRefId sort-id, Value value)
begin
    if value is nil or UNDEFINED return true
    else get the range for the sort-id and return appropriate value
end
\end{verbatim}

\subsection{Selecting a Partition}

In a system definition both the partitioned and unpartitioned version
of a block definition may appear.
In this case, the system definition
contains several consistent partitioning subsets, each corresponding
to a system instance.
Informally, a consistent partitioning is a
selection of the block definitions in a system definition such that:

\begin{itemize}
\item if it contains a block definition, then it must contain the
definition of the enclosing scope unit;
\item it must contain all the block definitions defined on the system
level and if it contains sub-block definitions of a block definition,
then it must also contain all other sub-block definitions of that
block definition;
\item all `leaf' block definitions in the resulting structure contain
process definitions.
\end{itemize}

At runtime the processes in each of the leaf blocks in the subset are
interpreted. If these leaf blocks also contain substructures they
have no effect. The substructures in the non-leaf blocks have an
effect on visibility, but the processes in these blocks are not
interpreted.

The use of consistent partitions is aimed at simplifying the
specification of a system through succesive hierachical 
decomposition.
As our aim is to analyse specifications for
performance and correctness, these constructs add unnecessary
complexity to the implementation. 
Although they have been implemented
in the parser, they will not be implemented in the code generator
and semantic checker at this stage.

\subsection{Construction of Communication Paths}

Each process descriptor in the entity dictionary includes a set of
reachabilities.
In every scope unit which contains channels between
two blocks, the incoming paths and outgoing paths
for the channels are constructed, the paths are joined, and the
process descriptors associated with the `outgoing' block are updated.

The partial paths contain, before they are joined, a channel at one
of the endpoints and a signal route at the other endpoint. 
The intermediate identifiers are all sub-channel identifiers.
Most of the complexity of the code below is due to the handling
of channel substructures, which we are not implementing.
The algorithm presented here is slightly simplified from the standard
as we do not handle partitioning, and thus do not need to check that
both ends are within the partition.

Eseentially the algorithm loops through all channels, finds all
possible paths from the two ends of the channel to a process or
the environment, takes all combinations of incoming and outgoing
paths associated with the channel and finds which subset of signals
can traverse that path, and then adds the resulting reachability to
the set of reachabilities of the source process.
A reachability is a 3-tuple {\tt \{ PId, SigSet, Path \}}
containing the destination process ID, the path to the destination,
and the set of signals that may be sent to that process via that
path. 
The result of the algorithm is the set of reachabilities for
each process. 
Each reachability is managed by its own {\em path} processor;
the {\tt pathmap} contains the CSP process IDs of these
processes, indexed by the reachability 3-tuple.

\begin{verbatim}
EntityDict make-structure-paths(BlockDefSet bset, ChanDefSet cset,
                                Qual level)(dict)
begin
    if (cset is empty) return dict
    else begin
        for each channel definition ch in cset do
        begin
            get { nm, { b1, b2 } } from ch
            if ((b1 or b2 is ENV) and level not system level
            then make-structure-paths(bset, cset-{ch}, level)(dict)
            else begin
                let chid = Identifier {level, nm }
                let {reachset1, dict'} = 
                      out-going-paths(chid, b1, bset, <> )(dict)
                let {reachset1', dict"} = 
                      out-going-paths(chid, b2, bset, <> )(dict')
                let reachset2 = in-coming-paths(chid, b2, bset, <> )
                let reachset2' = in-coming-paths(chid, b1, bset, <> )
                let d = update-processd(reachset1, reachset2)(dict")
                let d' = update-processd(reachset1', reachset2')(d)
                make-structure-paths(bset, cset-{ch}, level)(d')
            end
        end
    end
end
\end{verbatim}

\begin{verbatim}
{ReachSet EntityDict} out-going-paths(ChanId chid, BlockId b,
    BlockIdSet bset, Path path)(dict)
begin
    if (b is ENV) then return { { { ENV, <chid> } }, dict }
    get { level, bnm } from b
    get the bdef in bset with name bnm
    get { ,,,connects, srdefs,,,sub} from bdef
    let path' = path + <chid>
    let bqual = level + qualifier(bnm)
    get { ch, routeset } from connects such that ch = chid
    return make-out-reaches(routeset, srdefs, path')(dict)
end
\end{verbatim}

\begin{verbatim}
ReachSet in-coming-paths(ChanId cid, BlockId block,
    BlockIdSet bset, Path path)(dict)
begin
    if (block is ENV) then return { { { ENV, <chid> } }, dict }
    get { qual, bnm } from block
    get the bdef in bset with name bnm
    get { ,,,connects, srdefs,,,sub} from bdef
    let path' = path + <chid>
    let bqual = level + qualifier(bnm)
    get { ch, routeset } from connects such that ch = chid
    return make-in-reaches(routeset, srdefs, path')(dict)
end
\end{verbatim}

\begin{verbatim}
ReachSet make-in-reaches(SigRouteIdSet routeset, SigRouteDefSet srdefs,
     Path path)
begin
    if routeset is empty then return ( {}, {} )
    take an element route from routeset
    let reachrest = make-in-reaches(routeset - {route}, srdefs, path)
    get { , rnm } from route
    get {nm, path1, path2 } from srdefs such that nm = rnm
    get { e1, e2, sigset } from path1
    if (e1 is ENV) then
        let { signalset, dest } = { {}, e1 }
    else if path2 is nil then
        let { signalset, dest } = { sigset, e2 }
    else begin
        get { ,, sigset' } from path2
        let { signalset, dest } = { sigset', e1 }
    end
    return reachrest + { { dest, signalset, path+<route> } }
end
\end{verbatim}

\begin{verbatim}
{ReachSet EntityDict} make-out-reaches(SigRouteIdSet routeset,
    SigRouteDefSef routedefs, Path path) (dict)
begin
    if routedefs is empty return { {}, dict }
    take an element route from routedefs
    let { restr, restd } = 
        make-out-reaches(routeset, routedefs - {route}, path) (dict)
    get { rnm, { p1, p2, sset}, path } from route
    if p1 or p2 is ENV then
    begin
        let id be the elt of routeset with name rnm
        if path2 is nil then
            if p1 is ENV return { restr, restd }
            else return { restr + {p1, sset, <id>+path }, restd }
        else begin
            get { ,,sset'} from path2
            if p1 is ENV then
                let { originp, sset" } = { p2, sset' }
            else
                let { originp, sset" } = { p1, sset }
            return { restr + { originp, sset", <id>+path }, restd}
        end
    end
    else begin
        get { level, } from p1
        return { restr, make-local-reach(Ident{level, rnm}, route)(restd) }
    end
end
\end{verbatim}

\begin{verbatim}
EntityDict make-local-reach(SigRouteId id, SigRouteDef { rnm, path1, path2 })
begin
    get {p1, p2, sset } from path1
    get { parm, init, maxi, graph, inrset } from dict[ {p1, PROCESS} ]
    let reach = { p2, sset, <id> }
    let dict' = dict
    dict'[ {p1, PROCESS} ] = { parm, init, maxi, graph, inrset+{reach} }
    if (path2 = nil) then return dict'
    else return make-local-reach(id, {rnm, path2, nil})(dict')
end
\end{verbatim}

\begin{verbatim}
EntityDict update-processd(ReachSet outrset, ReachSet inrset)(dict)
begin
    if outrset is empty then return dict
    let outreach be an element of outrset
    get { pid, sigset, path } from outreach
    let inrset' be the set of incoming reachabilities that
        contain the continuation of the path; i.e. those with
        the same channel ID at the end of the path as the channel
        Id at the beginning of `path'
    get { parmd, init, maxi, graph, rset } = dict[ {pid, PROCESS } ]
    let reachabilityset = extract-reachabilities(sigset, path, inrset')
    let dict' = dict
    dict' [ {pid, PROCESS} ] = { parmd, init, maxi, graph, 
                                 rset + reachabilityset }
    update-processd(outrset - {outreach}, inrset)(dict')
end
\end{verbatim}

\begin{verbatim}
ReachSet extract-reachabilities(SigIdSet sigset, Path path, ReachSet inrset)
begin
    if (inrset is empty) return {}
    let inr be an element of inrset
    get { pid, sigset', path' } from inr
    let s = (intersection of sigset and sigset')
    if (s is empty) then reach = {}
    else reach = { pid, s, path + tail(path') }
    return { reach } + extract-reachabilities(sigset, path, inrset - {inr} )
end
\end{verbatim}

\section{Implementation}

We now consider semantic checking and code generation
using our version of the abstract syntax tree.
We also briefly discuss the changes in rewriting $AS_0$ to $AS_1$,
and how this relates to our AST, which lies between the two.

Each major construct is considered in a separate section. Each
section begins with a description of the corresponding AST node(s).
Three versions of each node are shown, namely (in left to right
order) the $AS_0$ node, our representation, and the $AS_1$
representation.

Note that we do not include channel substructures, service
definitions, or decompositions.

One general extension is the implementation of the special value {\tt
UNDEFINED}. The easiest (but not ideal) way to implement this is to
reserve a special value for this case. Other ways must still be
considered.

\subsection{The System}

\begin{verbatim}
System:
      Name              Name             Name
      Type*             Type*            Type*
      Signal*           Signal*          Signal*
      SignalList*       SignalList*      Syntype*
      Channel*          Channel*         Channel*
      Block*            Block*           Block*
      BlockRef*
      Selection*
    [ TailName ]
      RemoteDefinition*

BlockRef:
    Name
\end{verbatim}

\subsubsection{Rewriting}

We resolve block references and remote definitions in our AST,
and check the tail name. Our tree resembles the $AS_1$ form except
that we do not currently support syntypes, and we do not expand
references to signal lists and thus do not remove the signal list
definitions.

The selection of the consistent subset is performed on the $AS_1$
tree before it is interpreted by the abstract SDL machine.

Note that there is a considerable difference between data type
definition nodes in the $AS_0$ and $AS_1$ forms, although this
does not currently affect us as we provide a restricted type
definition mechanism.

\subsubsection{Semantic Checking}

A system must contain at least one block. 

The starting and ending
identifiers of remote block, process, procedure, service, channel
substructure, or block substructure definitions must match.
Remote definitions must all be referenced in the system
definition, and all references must have matching remote definitions.
Remote definitions must be unique.

Definining names may only be qualified in remote definitions.

In addition, the following semantic checks are applicable to the
whole system:

\begin{itemize}
\item definitions in the same scopeunit must have distinct names;
\item defining names may only be qualified in remote definitions
(syntactic check in our compiler);
\end{itemize}

\subsubsection{Code Generation}

We generate a {\tt system} e=code instruction with an offset to
an initialisation transition.
The latter should create a system for each block.
Because the number of instances of processes can be unbounded, we
cannot use module variables as in Estelle, so process creation will
be handled slightly differently to the Estelle case.

\subsection{Blocks}

\begin{verbatim}
Block:
      Ident                Name                Name
      Type*                Type*               Type*
      Connection*          Connection*         Connection*
      Signal*              Signal*             Signal*
      SignalList*          SignalList*         Syntype*
      SignalRoute*         SignalRoute*        SignalRoute*
      Process*             Process*            Process*
      ProcessRef*        [ Substructure ]    [ Substructure ]
      Selection*
    [ Substructure ]     
    [ TailIdent ]

ProcessRef:
      Name
    [ Initial ]
    [ Maximum ]
\end{verbatim}

\subsubsection{Rewriting}

Because we resolve remote references during parsing, we store the name,
not the identifier.
As with {\tt System}, we do not yet implement syntypes
and have not expanded signal list references.
We also do not handle selections yet.

\subsubsection{Semantic Checking}

Unless a block definition contains a substructure there must be at
least one process and one signalroute in the block.
A block substructure must contain a block definition.

\subsubsection{Code Generation}

Blocks are mapped onto SDL systems which are created by the top-level
system. 
`Block' systems are created once only, at initialisation
time.
They are responsible for creating systems for their subblocks
(once substructuring is implemented) or for their initial processes,
whichever is appropriate.
The formal parameters of initial processes
must be set to {\tt UNDEFINED}, and their 
{\tt PARENT}, {\tt SENDER} and {\tt OFFSPRING}
variables set to {\tt NULL}.

\subsection{Processes}

\begin{verbatim}
Process:
      Ident                 Name                  Name
    [ InitialInstances ]    InitialInstances      InitialInstances
    [ MaxInstances ]        MaxInstances          MaxInstances
      ProcessFormalParams*  ProcessFormalParams*  ProcessFormalParams*
    [ ValidInputSignal* ]   ValidInputSignal*     Type*
      Type*                 Type*                 Signal*
      Signal*               Signal*               Timer*
      Timer*                Timer*                Syntype*
      SignalList*           SignalList*           View*
      View*                 View*                 Variable*
      Import*               Import*               Procedure*
      Variable*             Variable*             Body
      Procedure*            Procedure*
      ProcedureRef*         Body
      Selection*
      ProcessBody
    [ TailIdent ]

ProcessFormalParams:
      Name+                  Name+                  Name
      SortID                 SortID                 SortID

ProcessBody:
      Body | Decomposition

Body:
      StartTransition        StartTransition        StartTransition
      State*                State*                State*           

ProcedureRef:
      Name
\end{verbatim}

\subsubsection{Rewriting}

We do not support selections or syntypes.
We resolve process
identifiers (checking the tail identifier) into names. 
We do not
expand signal list references, so we retain the definitions.

{\tt ValidInputSignalList}s are removed in $AS_1$ as they are no
longer required once the associated semantic checks have been done.

{\tt Import}s are removed in $AS_1$ by converting them to 
an exchange of signals.

\subsubsection{Semantic Checking}
\label{inferroute}

The initial and maximum number of process instances
can be obtained from the process definition or a
process reference; if present in both the values must agree
(if present in zero the defaults are one and unbounded).
{\tt InitialInstances} must be positive and not greater than
{\tt MaxInstances}, which must be greater than zero.

The names of the formal parameters must be distinct from each other
and from the local variables, and vice-versa.

Processes must use signals on the same refinement level (pg 61; not
applicable to us as we don't support signal refinements).

The valid input signal set must not contain timer signals.

If a process contains a procedure which contains states or imports
then the process must not contain services. Processes cannot contain
both service definitions and timer definitions.

If a block definition contains signal route definitions then the
valid input signal set, if any, need not contain signals in the
signal routes leading to the process. If the block definition
contains no signal routes then all processes in the block must have
valid input signal sets.
In this case the signal routes and channel to route connections are
inferred from the valid input signal sets, outputs, and the channels
terminating at the blocks boundary.

\subsubsection{Code Generation}

Each SDL process type is mapped on to on Estelle process type.
Each body transition in the process is mapped on to a transition in
the Estelle process. 
The StartTransition forms an initialisation part 
consisting of a single transition in the corresponding process.
This initialisation transition also has assignment statements
prepended to initialise local variables where required.

Estelle supports initialisation parameters for process instances,
so the same mechanism is reused for SDL process parameters.

\subsection{Procedures}

\begin{verbatim}
Procedure:
      Ident                   Name                    Name
      ProcedureFormalParams*  ProcedureFormalParams*  ProcedureFormalParams*
      Type*                   Type*                   Type*
      Variable*               Variable*               Syntype*
      Procedure*              Procedure*              Variable*
      ProcedureRef*           Body                    Procedure*
      Selection*                                      Body
      Body
    [ TailIdent ]

ProcedureFormalParams:
      Name+                   Name+                   Name
      IsInOut                 IsInOut                 IsInOut
      SortID                  SortID                  SortID
\end{verbatim}

\subsubsection{Rewriting}

We resolve identifiers into names, checking the tail identifier if
present. 
We do not support selections or syntypes at present.
The {\tt IsInOut} attribute is implicit in the standard, but explicit 
in our tree.

\subsubsection{Semantic Checking}

Variable definitions in procedures cannot be {\tt REVEALED}
and/or {\tt EXPORTED}. 

The names of formal parameters and local variables must be distinct
with respect to each other.

\subsubsection{Code Generation}

Local variables must be created for each {\tt IN} parameter, and assigned
the value passed, or {\tt UNDEFINED} if no value was passed. 
In/out parameters are like reference parameters in Estelle.

Procedures in Estelle are pure Pascal, and run to completion as part
of the execution of atomic transitions.
Procedures in SDL are
effectively substitute FSMs which can take control indefinitely 
until they execute a {\tt RETURN}.
We will not implenemt them at first. See section~\ref{sdlproc}
for more details.

\subsection{Channels}

\begin{verbatim}
Channel:
      Name                   Name                    Name
      ChannelPath1           ChannelPath1            ChannelPath1
    [ ChannelPath2 ]       [ ChannelPath2 ]        [ ChannelPath2 ]
    [ ChanSubstruct ]
    [ TailName ]

ChannelPath:
      SourceBlock            SourceBlock            SourceBlock
      DestinationBlock       DestinationBlock       DestinationBlock
      SignalID*              SignalID*              SignalID*

SourceBlock:
      BlockID | ENV          BlockID | ENV          BlockID | ENV

DestinationBlock:
      BlockID | ENV          BlockID | ENV          BlockID | ENV
\end{verbatim}

\subsubsection{Rewriting}

We check the tail name while parsing.
We do not support channel substructures at present.
Note that our {\tt Signal*} set in a
{\tt Path} can contain signal list IDs as well as signal IDs.

\subsubsection{Semantic Checking}

At least one end of a channel must be a block; if both are blocks
they must be different.
The block end-points must be defined in the same scope unit as the
channel is defined.
Where two channel paths are defined the one must be in the
reverse direction to the other.
The signal identifier set in the paths must contain all of the
signals that can be conveyed on the channel path(s) defined by the
channel.

\subsubsection{Code Generation}

No code is generated for channels, but channel information is used
to build the table of paths used for generating {\tt sdloutput}
instructions (see~\ref{deliver}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Signal Routes}

\begin{verbatim}
SignalRoute:
      Name                   Name                      Name
      SigRoutePath1          SigRoutePath1             SigRoutePath1
    [ SigRoutePath2 ]      [ SigRoutePathPath2 ]     [ SigRoutePath2 ]

SigRoutePath:
      SourceProcess          SourceProcess             SourceProcess
      DestinationProcess     DestinationProcess        DestinationProcess
      SignalID*              SignalID*                 SignalID*

SourceProcess:
      ProcessID | ENV        ProcessID | ENV           ProcessID | ENV

DestinationProcess:
      ProcessID | ENV        ProcessID | ENV           ProcessID | ENV
\end{verbatim}

\subsubsection{Rewriting}

Our {\tt Signal*} set in a {\tt Path} can contain signal list IDs as well.

\subsubsection{Semantic Checking}

At least one end of a signal route must be a process; if both are processs
they must be different.
The process end-points must be defined in the same scope unit as the
signal route is defined.
Where two signal route paths are defined the one must be in the
reverse direction to the other.
The signal identifier set in the paths must contain all of the
signals that can be conveyed on the signal route path(s) defined by the
signal route.

\subsubsection{Code Generation}

No code is generated for signal routes, but signal route information is used
to build the table of paths used for generating {\tt sdloutput}
instructions. See also sections~\ref{inferroute} and~\ref{deliver}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Connections}

\begin{verbatim}
C2RConnection:
                           ChannelID              ChannelID
                           SignalRouteID*         SignalRouteID*

ChannelConnection:
                           (not implemented)      ChannelID
                                                  SubChannelID*
\end{verbatim}

\subsubsection{Rewriting}

The $AS_0$ form is not shown here. In $AS_0$ no distinction is made
between channel connections, channel to route connections, channel
endpoint connections and signal route connections; each is
represented by a nonempty list of identifiers preceded by a
connectpoint, which is either an identifier or {\tt ENV}.

Channel connections are only used when connecting block
substructures, which we may not implement initially.

\subsubsection{Semantic Checking}

Block identifiers in connects must denote channel endpoints.

Each channel connected to the enclosing block, signal route,
service signal route or subchannel must appear in exactly one connection.

Each signal route must be defined in the same block and must have the
boundary of the block as one of its endpoints (i.e., the environment
of the block, which is the channels connected to the block).

For a given direction, the union of the signals in the signal routes
(service signal routes) in a connection must be equal to the set 
of signals conveyed by the channel (signal route) in that direction.

The set of channels having the block (substructure) as one of 
their endpoints must be equal to the set of channels mentioned in 
connects in the block (substructure).
Channel and channel to signal route connections must be well-formed (pg
126).

\subsubsection{Code Generation}

No code is generated for these, but the information is used
to build the table of paths used for generating {\tt sdloutput}
instructions. See also sections~\ref{inferroute} and~\ref{deliver}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Signals}

\begin{verbatim}
Signal:
      SignalElem+        Name              Name
                         SortID*           SortID*
                                         [ Refinement ]

SignalElem:
      Name               
      SortID*            
    [ Refinement ]       
\end{verbatim}

\subsubsection{Rewriting}
\label{collate}

Currently we don't implement signal refinements.

The difference between the $AS_0$ and $AS_1$ form is mainly because the
$AS_0$ tree orders definition nodes in the order they occur in the
specification. 
However, this order is not important, as data types
can always be placed before signal, timer and variable definitions,
followed by signal lists. 
As a result, both our tree and the $AS_1$
form do not preserve the original order. 
Signal lists below are
another example of an order-preserving versus a collating
representation.

\subsubsection{Semantic Checking}

The signal identifiers must be distinct.

\subsubsection{Code Generation}

Signal definitions constitute semantic (`symbol table') information
only; no code is generated for the definitions.
However, each signal
ID is allocated a unique small numeric index to assist in
representing sets of signals.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Signal Lists}

\begin{verbatim}
SignalList:
      Name                    Name
      SignalListElem+         Signals*
                              SignalLists*

SignalListElem:
      SignalID | SignalListID
\end{verbatim}

\subsubsection{Rewriting}

There is no corresponding construct in $AS_1$. The difference between
our form and the $AS_0$ form are due to ordering considerations,
described in~\ref{collate}.

\subsubsection{Semantic Checking}

Every signal identifier in a signal list must be distinct.

\subsubsection{Code Generation}

No code is generated for signal list definitions.
References to signal list IDs in saves, etc, are replaced by the 
set of signals in the list.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Variable Definitions}

\begin{verbatim}
VariableDefs:
      IsRevealed              IsRevealed          IsRevealed
      IsExported              IsExported          Name
      VariableDecl+           VariableDecl+       SortID

VariableDecl:
      Name+                   Name+
      SortID                  SortID
    [ ValueExpr ]           [ ValueExpr ]
\end{verbatim}

\subsubsection{Rewriting}

In $AS_1$ each variable definition is expanded to a node, while
$AS_0$ and our tree aggregate consecutive variables of the same type
into a single node.
In $AS_1$ the value expression is converted to
a sequence of assignment statements in the initial transition.

The {\tt IsExported} attribute is removed in $AS_1$ as exports are
converted to assignments from the explicit (exported) variable
to the implicit (imported) copy.

\subsubsection{Semantic Checking}

Variable names must be distinct from each other and from any formal
parameters associated with their scope unit.

\subsubsection{Code Generation}

No code is generated, but variables are allocated storage on the
process or procedure stack.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{View Definitions}

\begin{verbatim}
ViewDef:
      ViewDefElt+        VariableID+        VariableID
                         SortID             SortID

ViewDefElt:
      VariableID+
      Sort
\end{verbatim}

\subsubsection{Rewriting}

We use a more condensed form, grouping sequence of variable IDs of
the same sort together.

\subsubsection{Semantic Checking}

The variable definition designated by the VariableID must be {\tt
REVEALED} and must be of the same sort.

\subsubsection{Code Generation}

No code is generated; the information is used to check the validity
of view expressions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{States}

\begin{verbatim}
State:
      FromStates               FromStates                Name
      SaveSpec**               SaveSpec*                 SaveSignalID*
      InputSpec*               InputSpec*                InputSpec*
      PriInput*                PriInput*
      ContSpec*                ContSpec*

FromStates:
      StateName*               StateName*
    | StarredList              IsStarred

PriInput:
      InputVar+                InputSpec
      Transition

InputSpec:
      IsStarred | InputVar+    IsStarred	    InputVar
    [ EnblExpr ]               InputVar+            Transition
      Transition	     [ EnblExpr ]
			       Transition

InputVar:
      SignalID                SignalID              SignalID
    [ VarId ]*              [ VarID* ]            [ VarID* ]

StarredList:
    [ StateName* ]

SaveSpec:
      SignalID*               SignalID*
    | IsStarred		      IsStarred
\end{verbatim}

\subsubsection{Rewriting}

When the state list contains more than one state name, a copy of the
state is created for each such name, and the state is replaced by
these copies in $AS_1$. Note that in $AS_1$, the save signal set and
the input node set include any implicit saves and inputs.

When the stimulus list of a certain input part contains more than one
stimulus, a copy of the input part is created for each such stimulus,
and in $AS_1$ the input part is replaced by these copies.

Note that the signal identifiers are used to represent timer
inputs as well. In many respects, timers are just like signals.

Priority inputs form part of service definitions which we
are not implementing at first. To implement priority inputs
in $AS_1$, each state is split into two, one for priority inputs and
one for non-priority inputs (See Z.100, sec 4.10.2).

The enabling condition is rewritten in $AS_1$ by introducing new
transitions and signals. See 4.12 of Z.100 for details. As we can use the
Estelle {\tt PROVIDED} clause we do not need to do this complex
rewrite.

Asterisk saves and inputs are transformed in $AS_1$ to lists of stimuli
containing the complete valid input signal set of the enclosing
process or service definition, except for signal identifiers of
implicit signals and other inputs and save lists of the state,
and in all priority inputs of the service definition.

Asterisk state lists are transformed to a list containing all of the
states, except those mentioned in the list, if any.

A state name may appear in more than one state ; these states are
then concatenated into one state having the same name.

The primary differences between our representation and $AS_0$ are due
to the class library implementation; our representation can
effectively be considered the same as $AS_0$ here.

\subsubsection{Semantic Checking}

The state name list specified in a state must contain distinct
names. If a state name list is specified in the state then if a
tailing name is specified then the state name list must consist of
the same name. If an asterisk state name list is specified then a 
tailing name is not allowed.

There must be at least one state which is not an asterisk
state, and a state cannot have more than one asterisk input or save.

Signals in a state must be disjoint.

Only one continuous signal may be specified if the priority is
omitted (pg 182); continuous signals must have distinct priorities.

\subsubsection{Code Generation}

With the exception of saves (which we will implement by extending the
{\tt when} e-code instruction) and priority inputs (which we are
not implementing), the constructs in an
SDL state can be mapped onto enabling clauses of Estelle transitions.
The {\tt sender} variable must also be updated in the receiving
process.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Transitions}

\begin{verbatim}
Transition:
      ActStmt*                 ActStmt*                Act*
    [ TermStmt ]               TermStmt              ( Terminator | Decision )

ActStmt:
    [ LabelName ]            [ LabelName ]             Act
      Act                      Act

Act:
      Task                     Task                    Task
    | Output                 | Output                | Output
    | Create                 | Create                | Create
    | Decision               | Decision              | Call
    | Export                 | Export                | Set
    | Option                 | Call                  | Reset
    | Call                   | PriOutput
    | PriOutput              | Set
    | Set                    | Reset
    | Reset

TermStmt:
    [ LabelName ]            [ LabelName ]
      Terminator               Terminator

Terminator:
      NextState                NextState               NextState
    | Join                   | Join                  | Stop
    | Stop                   | Stop                  | Return
    | Return                 | Return

NextState:
    [ StateName ]              StateName               StateName

Join:
      LabelName                LabelName

Stop:
      empty                    empty                   empty

Return:
      empty                    empty                   empty
\end{verbatim}

\subsubsection{Rewriting}

A dash nextstate is replaced with the name of the state.

Our representation is effectively the same as $AS_0$.

Labels and joins are removed in $AS_1$, and replaced by ??
(see pg 60 of Z.100; doesn't mean anything to me though).

Priority outputs are allowed in service definitions only,
which we are not implementing (see Z.100 sec 4.10.2).
We must remove these from our tree.

\subsubsection{Semantic Checking}

The last action in a transition must have a terminator (pg
166); similarly if the action list is empty.

All the labels within a process must be distinct.

Dash nextstate is not allowed in initial transition.
A name in a nextstate must denote a defined state.
Labels in joins must be defined.

An option question must match one and only one answer.

Procedure graphs may not have stop nodes, and process graphs may not
have return nodes.

\subsubsection{Code Generation}

These map to corresponding Estelle constructs, except for priority
outputs (which are part of service definitions, which we are
not implementing) and exports. 
Also, the semantics of create and output are
somewhat different.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task}

\begin{verbatim}
Task:
      Assignment+              Assignment              Assignment

Assignment:
      VariableID               VariableID              VariableID
      Expr                     Expr                    Expr
\end{verbatim}

\subsubsection{Rewriting}

We keep each assignment in a separate node as in $AS_1$. This is a
minor issue.

\subsubsection{Semantic Checking}

The type of the expression and the variable must be compatible.

\subsubsection{Code Generation}

This corresponds to an Estelle assignment statement.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Create and Call}

\begin{verbatim}
Create:
      ProcessID                ProcessID               ProcessID
    [ Expr ]*                [ Expr ]*               [ Expr ]*

Call:
      ProcessID                ProcessID               ProcessID
    [ Expr ]*                [ Expr ]*               [ Expr ]*
\end{verbatim}

\subsubsection{Rewriting}

There is no distinction between the various forms here. Note the
position of the kleene star - this implies that the list of arguments
exists but that entries in the list may be empty/optional,
as opposed to being an optional list of expressions.

\subsubsection{Semantic Checking}

The actual parameter list length must be equal to the formal
parameter list length.
Parameters must be of the correct type.
Procedure reference parameters must be variables.

\subsubsection{Code Generation}

We will implement an alternative version of the {\tt init}
e-code instruction for creating SDL processes.
The {\tt offspring} variable in the parent and {\tt parent} variable
in the child must be set accordingly.
If the create fails because the maximum allowed number of instances
is exceeded, the initiator must have its {\tt offspring} variable set
to {\tt NULL}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Output}

\begin{verbatim}
Output:
      OutputSig+               OutputSig+              OutputSig
    [ PIDExpr ]              [ PIDExpr ]             [ PIDExpr ]
      Via                      Via                     Via

OutputSig:
      SignalID                 SignalID                SignalID
    [ Expr ]                 [ Expr* ]               [ Expr ]

PIdExpr:
      Expr                     Expr                    Expr
    | ScopeExpr

ScopeExpr:
      Qualifier
      Expr

Via:
      ID*                      ID*                     SigRouteID*
\end{verbatim}

\subsubsection{Rewriting}

{\tt ScopeExpr} has no corresponding construct in the concrete
syntax; it is used in $AS_0$ to ease the transformation of services.
{\tt ScopeExpr}s are generated during the expansion of enabling
condition and continuous signals.

We use the slightly more compact $AS_0$ representation .

\subsubsection{Semantic Checking}

If an output is contained in a process then it must not be a
high priority output, and if it is a high priority output then there
must exist a receiving service and vice-versa.

The identifier in an output action must denote a signal and
must have the right number of arguments.
Signals in outputs must have a receiver.

Signal routes/channels may not be specified twice in a VIA set.
If signal routes are specified then channels cannot be
mentioned in a VIA.
The channel in a VIA set must be connected to the block.
The signal in an output must be conveyable by the channel in a
VIA set.

\subsubsection{Code Generation}

See section~\ref{deliver}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Decisions and Transition Options}

\begin{verbatim}
Decision:
      Question                 Question                Question
      Answer+                  Answer+                 Answer+
    [ ElsePart ]                                     [ ElsePart ]

Option:
      Question
      Answer+
    [ ElsePart ]

Question:
      Expr                     Expr?                   Expr
    | ScopeExpr

ElsePart:
      Transition                                       Transition

Answer:
      Condition*               RangeCondition*         RangeCondition
    [ Transition ]             Transition              Transition
\end{verbatim}

\subsubsection{Rewriting}

In our case the {\tt ElsePart} is stored as the last answer, rather
than being kept separately.

Transition options are deleted in $AS_1$ and replaced by the
contained selected constructs. This is effectively the same as
conditional compilation using selections.

\subsubsection{Semantic Checking}

If a transition has no else part and none of the answers is 
applicable this is an error.

\subsubsection{Code Generation}

Decisions correspond to the {\tt IF-THEN-ELSE} construct of Estelle.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Timers}

\begin{verbatim}
TimerDef:
      TimerElem+               TimerElem               TimerElem

TimerElem:
      TimerName                TimerName               TimerName
      SortID*                  SortID*                 SortID*

Set:
      SetElem+                 SetElem                 SetElem

SetElem:
      TimeExpr                 TimeExpr                TimeExpr
      TimerID                  TimerID                 TimerID
      Expr*                    Expr*                   Expr*

Reset:
      ResetElem+               ResetElem               ResetElem

ResetElem:
      TimerID                  TimerID                 TimerID
      Expr*                    Expr*                   Expr*
\end{verbatim}

\subsubsection{Rewriting}

Our representation is the same as the slightly expanded form used in $AS_1$.

\subsubsection{Semantic Checking}

Identifiers in set/reset actions must be timers, and must have a
parameter list of the same length as the definition.

\subsubsection{Code Generation}

Setting a timer will place a timestamped signal into the process'
input port queue. Resetting a timer will remove any such signal
from the queue. Resetting an inactive timer does nothing; setting an
active timer does a implicit reset followed by a set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Block Substructures}

\begin{verbatim}
BlockSub:
      BlockSubDef              Name                      Name
    | BlockSubRef              BlockDef*                 BlockDef*
                               ChanConn*                 ChanConn*
                               ChanDef*                  ChanDef*
                               SigDef*                   SigDef*
                               SigListDef*               DataDef*
                               DataDef*                  SyntypeDef*

BlockSubDef:
    [ BlockSubID ]
      BlockSubDecl+
    [ TailID ]

BlockSubDecl:
      SignalListDef
    | Connect
    | BlockDef
    | BlockRef
    | ChanDef
    | SigDef
    | DataDef
    | Select

BlockSubRef:
      Name

ChanConn:
                               ChannelID                 ChannelID
                               SubChannelID*             SubChannelID*   
\end{verbatim}

\subsubsection{Rewriting}

We resolve the identifier during parsing to a name, checking that the
tail identifier matches if present. We do not yet support syntypes or
selections. Our representation is similar to $AS_1$ except that we
retain signal list definitions and do not have syntypes.

\subsubsection{Semantic Checking}

A block substructure definition must contain at least one (sub-)block
definition. 

A block ID contained in a channel definition must denote a sub-block
definition.

For each external channel definition connected to the block
substructure definition there must be exactly one channel connection,
in which the channel ID identifies this external channel definition.

For signals directed out of the block substructure, the signal IDs in
the sub channels must equal those in the channel. Each subchannel
must appear in exactly one channel connection.
\subsubsection{Code Generation}

These will eventually be implemented as passive processes much like
blocks.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Types}

\begin{verbatim}
DataDef:
                               Name
                               Contents
                               IsStruct | IsArray

Contents:
                               Fields*
                             | Dimension Sort

Fields:
                               Name*
                               Sort
\end{verbatim}

We use a much simplified data type mechanism to SDLs, supporting a
subset of the predefined types, and array and structure user-defined
types. These can be combined, thus we can have arrays of structures
and structures containing arrays. These are adequate for almost all
purposes. We may include subranges as well at some point.

As a consequence of our simplification, we show only our AST 
representation here.

No code is generated for data definitions, but structure fields are
allocated offsets within the structure, and the size of data types is
computed, to assist in allocating storage and addressing variables
of these types.

Structure fields must have unique names.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Selections}

\begin{verbatim}
Select:
       Expr
       Decl+

Decl:
      BlockDef
    | BlockRef
    | ChanDef
    | SigDef
    | ProcessDef
    | ProcessRef
    | ProcedureDef
    | ProcedureRef
    | ServiceDef
    | ServiceRef
    | DataDef
    | SigRouteDef
    | SignalListDef
    | VarDef
    | ImportDef
    | ViewDef
    | TimerDef
    | Connect
    | Select
\end{verbatim}

\subsubsection{Rewriting}

In rewriting to $AS_1$, the expression is evaluated, and if {\tt
TRUE}, the definitions are included in the system (and partition),
in place of the original selection.
As a consequence there is no $AS_1$ representation. 

Currently we do not support selections, although adding support for
them is not difficult.

\subsubsection{Semantic Checking}

Definitions in {\tt select} are not allowed in channel
substructure? (F.2 pg 39, line 143) (syntactic check in our parser).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Priority Output}

\begin{verbatim}
PriOutput:
      OutputSig+
\end{verbatim}

\subsubsection{Rewriting}

Priority outputs are replaced in $AS_1$ with normal outputs, after a
complex rewriting process for the service definition; see 4.10.2 in
Z.100.

\subsubsection{Code Generation}

We are not implementing service definitions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Continuous Signals}

\begin{verbatim}
ContSpec:
      Expr                    Expr
      Priority                Priority
      Transition              Transition

Priority:
    [ Name ]
\end{verbatim}

\subsubsection{Rewriting}

These are rewritten in $AS_1$ by introducing an implicit variable and
an implicit signal that conveys the value of the variable,
introducing new transitions and input parts, and converting the
boolean expressions in continuous signals into a decision in
priority-order. See 4.11 in Z.100 for details.

\subsubsection{Semantic Checking}

The priorities of all continuous signals in a state must be distinct.
The priority may be omitted only if there is just one continuous
signal in the state. The expression must be a boolean.

\subsubsection{Code Generation}

These correspond to Estelle {\tt PROVIDED} and {\tt PRIORITY}
clauses.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Imports and Exports}

\begin{verbatim}
Export:
      VarID+

ImportDef:
      ImportElem+              ImportElem

ImportElem:
      VarName+                 VarName+
      SortID                   SortID

ImportExpr:
      VarID
    [ Expr ]
\end{verbatim}

\subsubsection{Rewriting}

The SDL model allows processes to access variables belonging to
other processes within the same block. The export/import construct
extends this to processes in other blocks. In $AS_1$ this is
rewritten to be implemented via an exchange of signals.

\subsubsection{Code Generation}

We will implement both viewing/revealing and importing/exporting with
an extension to the {\em PEW} interpreter (see section~\ref{viewproc}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Expressions}

\begin{verbatim}
Expr:
      ID                       Operand0               GroundExpr
    | StringTerm             [ IMPLY                | ActiveExpr
    | CondExpr		       Expr ]               | OperatorApp
    | MonadExpr
    | InfixExpr
    | ImpOperator
    | SelectExpr
    | TupleExpr

Operand0:		       
                               Operand1
                             [ ( OR | XOR )
                               Operand0 ]

Operand1:		       
                               Operand2
                             [ AND
                               Operand1 ]

Operand2:
                               Operand3
                             [ Relop
                               Operand2 ]

Operand3:
                               Operand4
                             [ ( MINUS | PLUS | CONCAT )
                               Operand3 ]

Operand4:
                               Operand5
                             [ ( ASTERISK | SLASH | MOD | REM )
                               Operand4 ]

Operand5:
                             [ ( MINUS | NOT ) ]
                               Primary

Primary:
                               StringTerm
                             | IntegerLiteral
                             | Expr
                             | VariableRef
                             | CondExpr
                             | ImpOperator

VariableRef:
                               VariableID
                             [ Selector* ]

Selector:
                               ArraySelector
                             | FieldSelector

ArraySelector:
                               Expr

FieldSelector:
                               FieldID

ActiveExpr:
                                                      VariableID
                                                    | CondExpr
                                                    | OperatorApp
                                                    | ImpOperator

GroundExpr:
                                                      LiteralOpID
                                                    | OpID GroundExpr+
                                                    | (Ground)CondExpr

StringTerm:
      Qualifier
      String

MonadExpr:
    ( NOT | MINUS )
      Expr

InfixExpr:
      Expr
      InfixOp
      Expr

InfixOp:
      IMPLY
    | OR
    | XOR
    | AND
    | IN
    | MOD
    | REM
    | PLUS
    | MINUS
    | CONC
    | MULT
    | DIV
    | Relop

Relop:
      NE
    | EQ
    | GT
    | LT
    | LE
    | GE

SelectExpr:
      Expr
      Name

TupleExpr:
     Qualifier
     Expr+

CondExpr:
      Expr                                           BooleanExpr
      Expr                                           Expr
      Expr                                           Expr

OperatorApp:
    ( Expr | QualOp )                                OperatorID
      Expr+                                          Expr+

QualOp:
      Qualifier
      QuotedOp

QuotedOp:
      InfixOp | NOT

ExprList:
      Expr*

ImpOperator:
      ImportExpr                                    
    | ViewExpr                                       ViewExpr
    | NowExpr                                      | NowExpr
    | ActiveExpr                                   | ActiveExpr
    | ParentExpr                                   | ParentExpr
    | OffspringExpr                                | OffspringExpr
    | SenderExpr                                   | SenderExpr
    | SelfExpr                                     | SelfExpr

ActiveExpr:
      TimerID
      ExprList
\end{verbatim}

\subsubsection{Rewriting}

{\tt ImportExpr}'s are rewritten in $AS_1$ as view expressions.

Our expression representation is quite different to the standard.
This is partly due to our simplified data types, as well as the
fact that we cannot have recursively nested classes. We also
use the tree to represent operator precedences, in line with more
typical expression grammars.

An SDL `ground' expression is an expression that can be evaluated
statically; i.e. it contains only literals at the bottom level of
term expansion.

\subsubsection{Semantic Checking}

Simple expressions must be of predefined sorts and cannot contain any
undefined identifiers.

Due to our simplified data types, we perform a subset of checks on
expressions and data types:

\begin{itemize}
\item type mismatches in expressions and assignments;
\item arrays indices out of range;
\item ground expressions may contain array and field references
but not imports, views, {\tt now}, select expressions, {\tt active}
expressions, or PID expressions;
\item view expressions must match one and only one revealed variable;
\item import variables must exist;
\item {\tt now} expressions can only be used where {\tt time} values
are allowed;
\item identifiers in timer expressions must denote timers;
\item {\tt active} expressions can only be used in contexts that
allow booleans;
\item identifiers must be visible where they are used;
\item signal lists must not be recursively defined;
\item signal identifiers may not denote more than one (sub)signal (pg
159);
\item identifiers must uniquely determine the objects they denote,
given the identifier and the expected set of types that it may have;
\end{itemize}

\subsubsection{Code Generation}

Code for expressions will be as for Estelle. 
The result of computing the value of an expression is left on the stack.
Where a ground
expression is expected we will attempt to evaluate the expression
statically; if this is not possible it is a semantic error.
A few new e-code
instructions are required for operators that have no match in
Estelle.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Service Decompositions}

We do not implement service decompositions. It is worth noting the
following related semantic checks, however:

\begin{itemize}
\item service decompositions cannot have signal route definitions,
connect definitions, or service definitions
(syntactic check in our compiler);
\item variables in service decompositions cannot be exported or
revealed;
\item only one service can contain an initial transition string;
\item the endpoints of service signal routes must be different.
\end{itemize}

\section{Interpreter Interface}

A drawback of the {\em PEW} was that the process browser under MS-DOS
was not portable.
Also, as work with the {\em PEW} continued, more and more
statistics-gathering capabilities were built into the interpreter,
bloating and obscuring the code and slowing down the system.
Ultimately these statistics proved to be inflexible, and eventually a
simple trace capability was added, which primarily just produced a
list consisting of (time, process ID, transition index) triples
representing the firing of transitions. A few simple filter programs
were written and as a result, much more flexible statistics could
be gathered.

A lesson to be learned from this is that the interface to the 
interpreter should be a simple, textual one. Textual commands
should be issued, and textual trace information returned.
Accumulation and processing of statistical information should be
done separately based on the ongoing trace information. This allows
almost unlimited flexibility without having to modify the
interpreter.

Using such a mechanism, a graphical user interface can still be built
which translates requests using menus, dialog boxes, etc, into 
textual commands, reads the information returned by the interpreter,
and displays this in a useful fashion. Effectively the interpreter
becomes a server, while the user interface becomes a client.

We now propose a small but powerful command set for the interpreter.
The first command, show ({\tt s}), specifies what information is
included in the interpreter output trace. It can be followed
by one or more trace type specifiers, namely:

\begin{tabular}{ll}
{\tt t} & trace transition firings\\
{\tt o} & trace signal outputs\\
{\tt a} & trace signal arrivals\\
{\tt i} & trace dequeueing of signals\\
{\tt c} & trace changes in clause states\\
{\tt l} & trace changes in source code line numbers\\
{\tt p} & trace process creation and termination\\
\end{tabular}

To turn off a trace the {\tt s} command can be preceded by {\tt -}.
If no trace type specifiers are included, then this is the same
as specifying all types. Thus all traces can be turned off with 
`{\tt -s}' or on with `{\tt +s}'.

The information output by the interpreter for signals will include
the time, sending process, receiving process, interaction point
(Estelle only) and signal. 
For clauses the interpreter will output a line any time the state of
any transition's when/input, delay (Estelle), or provided clause changes.
The line numbers option is provided for synchronising a source code
display with the execution. This is supported by the Estelle
compiler, but not by the SDL compiler at present.

In every case the first two fields on any output line are the
time of the event and the process ID of the firing/receiving/changing
process.

The run ({\tt r}) command controls the execution of the 
interpreter. With no arguments, the {\tt r} command causes
the interpreter to execute until it receives a interruption.
Otherwise an execution unit can be specified preceded by an optional
count (default is one).
The execution unit may be an e-code
operation ({\tt e}), a source line ({\tt l}), 
a transition ({\tt t}), a scheduler iteration ({\tt i}),
a time unit ({\tt u}), a trace output message ({\tt o}),
or until the next choice ({\tt c}, see below).
Thus, for example, to execute for
1000 time units, one could use `{\tt r1000u}'.

The quit ({\tt q}) command exits.

These commands are all that are needed for normal operation. For example,
breakpoints could be implemented by using step repeatedly on the
e-code instruction level and inspecting the output of the interpreter
to see if the breakpoint event(s) have occurred. This can be built
into a higher level user interface such as a future GUI.

However, in order to prevent duplication of the symbol table/AST in
the GUI, we can add a command to retrieve useful information,
in particular the names/identifiers of entities in the specification,
and the line number in the specification where the entities are
defined. This command is get ({\tt g}), and is followed by an object
type identifier (either {\tt p} for process ID or {\tt s} for
signal), and the internal identifier number or symbolic name.
If the object was a process, then the command can also be followed
by a transition/state index preceded by {\tt t}, which then refers
to a transition in a process rather than the process itself.
The output should be the defining line number (of the process, signal
or transition) and the name (of the process or signal).

One final command which is not essential but may be useful is a
filter command {\tt f} to reduce the output of the interpreter.
The {\tt f} should be preceded by a {\tt +} (to accept) or {\tt -}
(to reject), and followed by a number of fields. These are matched
against potential output lines that contain the same
number of fields. A field value of {\tt *} matches any actual
value. If the line matches an accept filter or does not
match any reject filter, it should be output. `{\tt ?f}' can be
used to list all filters, and `{\tt !f}' to delete filter(s).
A filter command can include a number after the {\tt +} or {\tt -};
once that many output lines have been filtered the filter can be
removed (in the case of {\tt -}) or activated (in the case of {\tt
+}).

Filters could be used to implement breakpoints directly, by filtering
all traced information except that which should cause a breakpoint,
and running until the next trace output. The numeric arguments to
filters can be used to implement breakpoint pass counts.
For example, the following sequence of commands will execute the
system until line 123 is executed for the 99th time:

\begin{verbatim}
-s
sl
-f   * * *
+98f * * 123
ro
\end{verbatim}

This instructs the interpreter to show only changes in the source line
number but filter all such change messages out. After line 123 has
been executed 98 times, an accept filter is activated for it. The
next time it is executed the trace line will be output. Finally,
execution is started and stops when the trace line is output.

It must also be possible to instruct the interpreter to redirect the
trace output to a file as well as standard output.

To implement the behaviour graph technique or state-space searching,
additional commands are needed. The {\tt c} argument to the {\tt r}
command must cause the specification to run until the next choice
(either the scheduler choosing which transition to execute next,
or a choice of whether to lose a signal or not). A list of choices
should be output together with a state hash value, and the next input
should be which choice to use.

This provides the necessary control over execution for state-space
searching. In addition, the state hash value can be used to determine 
whether a state has been visited before. For the behaviour graph
technique, the {\tt sf} command can be used to obtain the transition
sequences between each choice. A restriction is that transitions may
not contain more than one unreliable output.

\section{Doing the Implementation}

There are four tasks that will be performed in parallel:

\begin{itemize}
\item converting the existing interpreter into a class library,
modifying it to handle extensions to the e-code, and building the new
textual interface described above;
\item removing existing semantic checks from the parser except
for checking that identifiers at start and end of constructs match
(doing this in the parser saves space in the AST),
and disabling parsing of constructs not being handled in the initial
version, where parsing has already been implemented;
\item creating {\tt CheckSemantics} methods for the AST node classes
to perform semantic checking. A {\tt Rewrite} stub method will
be written for future extensions (such as selection handling and
choosing a consistent subset);
\item creating {\tt AllocateAddress} and {\tt GenerateCode} methods
for each relevant class in the AST.
\end{itemize}

\end{document}

